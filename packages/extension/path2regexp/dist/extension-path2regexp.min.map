{"version":3,"names":["dist","parse","compile","path","options","encode","encodeURIComponent","delimiter","DEFAULT_DELIMITER","data","TokenData","fn","tokensToFunction","tokens","missing","length","TypeError","join","match","decode","decodeURIComponent","regexp","keys","pathToRegexp","decoders","map","key","NOOP_VALUE","type","value","split","input","m","exec","params","Object","create","i","undefined","decoder","name","stringify","stringifyToken","token","index","escapeText","str","replace","isSafe","isNameSafe","first","rest","ID_START","test","every","char","ID_CONTINUE","isNextNameSafe","JSON","DEBUG_URL","SIMPLE_TOKENS","escape","Iter","constructor","this","peek","_peek","next","tryConsume","consume","nextType","text","result","encodePath","it","lexer","chars","pos","endType","push","param","wildcard","open","encoders","tokenToFunction","encodeValue","Array","isArray","encoder","extras","end","sensitive","trailing","sources","flags","paths","items","seq","flatten","sequenceToRegExp","pattern","RegExp","init","fork","slice","backtrack","isSafeSegmentParam","negate","includes","path2regexp","p2rTokenData"],"sources":["cdp:///@cdp/extension-path2regexp/path-to-regexp/src/index.ts","cdp:///@cdp/extension-path2regexp/index.ts"],"sourcesContent":["const DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = (value: string) => value;\nconst ID_START = /^[$_\\p{ID_Start}]$/u;\nconst ID_CONTINUE = /^[$\\u200c\\u200d\\p{ID_Continue}]$/u;\nconst DEBUG_URL = \"https://git.new/pathToRegexpError\";\n\n/**\n * Encode a string into another string.\n */\nexport type Encode = (value: string) => string;\n\n/**\n * Decode a string into another string.\n */\nexport type Decode = (value: string) => string;\n\nexport interface ParseOptions {\n  /**\n   * A function for encoding input strings.\n   */\n  encodePath?: Encode;\n}\n\nexport interface PathToRegexpOptions {\n  /**\n   * Matches the path completely without trailing characters. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * Allows optional trailing delimiter to match. (default: `true`)\n   */\n  trailing?: boolean;\n  /**\n   * Match will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\nexport interface MatchOptions extends PathToRegexpOptions {\n  /**\n   * Function for decoding strings for params, or `false` to disable entirely. (default: `decodeURIComponent`)\n   */\n  decode?: Decode | false;\n}\n\nexport interface CompileOptions {\n  /**\n   * Function for encoding input strings for output into the path, or `false` to disable entirely. (default: `encodeURIComponent`)\n   */\n  encode?: Encode | false;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\ntype TokenType =\n  | \"{\"\n  | \"}\"\n  | \"WILDCARD\"\n  | \"PARAM\"\n  | \"CHAR\"\n  | \"ESCAPED\"\n  | \"END\"\n  // Reserved for use or ambiguous due to past use.\n  | \"(\"\n  | \")\"\n  | \"[\"\n  | \"]\"\n  | \"+\"\n  | \"?\"\n  | \"!\";\n\n/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type: TokenType;\n  index: number;\n  value: string;\n}\n\nconst SIMPLE_TOKENS: Record<string, TokenType> = {\n  // Groups.\n  \"{\": \"{\",\n  \"}\": \"}\",\n  // Reserved.\n  \"(\": \"(\",\n  \")\": \")\",\n  \"[\": \"[\",\n  \"]\": \"]\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"!\": \"!\",\n};\n\n/**\n * Escape text for stringify to path.\n */\nfunction escapeText(str: string) {\n  return str.replace(/[{}()\\[\\]+?!:*]/g, \"\\\\$&\");\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escape(str: string) {\n  return str.replace(/[.+*?^${}()[\\]|/\\\\]/g, \"\\\\$&\");\n}\n\n/**\n * Tokenize input string.\n */\nfunction* lexer(str: string): Generator<LexToken, LexToken> {\n  const chars = [...str];\n  let i = 0;\n\n  function name() {\n    let value = \"\";\n\n    if (ID_START.test(chars[++i])) {\n      value += chars[i];\n      while (ID_CONTINUE.test(chars[++i])) {\n        value += chars[i];\n      }\n    } else if (chars[i] === '\"') {\n      let pos = i;\n\n      while (i < chars.length) {\n        if (chars[++i] === '\"') {\n          i++;\n          pos = 0;\n          break;\n        }\n\n        if (chars[i] === \"\\\\\") {\n          value += chars[++i];\n        } else {\n          value += chars[i];\n        }\n      }\n\n      if (pos) {\n        throw new TypeError(`Unterminated quote at ${pos}: ${DEBUG_URL}`);\n      }\n    }\n\n    if (!value) {\n      throw new TypeError(`Missing parameter name at ${i}: ${DEBUG_URL}`);\n    }\n\n    return value;\n  }\n\n  while (i < chars.length) {\n    const value = chars[i];\n    const type = SIMPLE_TOKENS[value];\n\n    if (type) {\n      yield { type, index: i++, value };\n    } else if (value === \"\\\\\") {\n      yield { type: \"ESCAPED\", index: i++, value: chars[i++] };\n    } else if (value === \":\") {\n      const value = name();\n      yield { type: \"PARAM\", index: i, value };\n    } else if (value === \"*\") {\n      const value = name();\n      yield { type: \"WILDCARD\", index: i, value };\n    } else {\n      yield { type: \"CHAR\", index: i, value: chars[i++] };\n    }\n  }\n\n  return { type: \"END\", index: i, value: \"\" };\n}\n\nclass Iter {\n  private _peek?: LexToken;\n\n  constructor(private tokens: Generator<LexToken, LexToken>) {}\n\n  peek(): LexToken {\n    if (!this._peek) {\n      const next = this.tokens.next();\n      this._peek = next.value;\n    }\n    return this._peek;\n  }\n\n  tryConsume(type: TokenType): string | undefined {\n    const token = this.peek();\n    if (token.type !== type) return;\n    this._peek = undefined; // Reset after consumed.\n    return token.value;\n  }\n\n  consume(type: TokenType): string {\n    const value = this.tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = this.peek();\n    throw new TypeError(\n      `Unexpected ${nextType} at ${index}, expected ${type}: ${DEBUG_URL}`,\n    );\n  }\n\n  text(): string {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = this.tryConsume(\"CHAR\") || this.tryConsume(\"ESCAPED\"))) {\n      result += value;\n    }\n    return result;\n  }\n}\n\n/**\n * Plain text.\n */\nexport interface Text {\n  type: \"text\";\n  value: string;\n}\n\n/**\n * A parameter designed to match arbitrary text within a segment.\n */\nexport interface Parameter {\n  type: \"param\";\n  name: string;\n}\n\n/**\n * A wildcard parameter designed to match multiple segments.\n */\nexport interface Wildcard {\n  type: \"wildcard\";\n  name: string;\n}\n\n/**\n * A set of possible tokens to expand when matching.\n */\nexport interface Group {\n  type: \"group\";\n  tokens: Token[];\n}\n\n/**\n * A token that corresponds with a regexp capture.\n */\nexport type Key = Parameter | Wildcard;\n\n/**\n * A sequence of `path-to-regexp` keys that match capturing groups.\n */\nexport type Keys = Array<Key>;\n\n/**\n * A sequence of path match characters.\n */\nexport type Token = Text | Parameter | Wildcard | Group;\n\n/**\n * Tokenized path instance.\n */\nexport class TokenData {\n  constructor(public readonly tokens: Token[]) {}\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): TokenData {\n  const { encodePath = NOOP_VALUE } = options;\n  const it = new Iter(lexer(str));\n\n  function consume(endType: TokenType): Token[] {\n    const tokens: Token[] = [];\n\n    while (true) {\n      const path = it.text();\n      if (path) tokens.push({ type: \"text\", value: encodePath(path) });\n\n      const param = it.tryConsume(\"PARAM\");\n      if (param) {\n        tokens.push({\n          type: \"param\",\n          name: param,\n        });\n        continue;\n      }\n\n      const wildcard = it.tryConsume(\"WILDCARD\");\n      if (wildcard) {\n        tokens.push({\n          type: \"wildcard\",\n          name: wildcard,\n        });\n        continue;\n      }\n\n      const open = it.tryConsume(\"{\");\n      if (open) {\n        tokens.push({\n          type: \"group\",\n          tokens: consume(\"}\"),\n        });\n        continue;\n      }\n\n      it.consume(endType);\n      return tokens;\n    }\n  }\n\n  const tokens = consume(\"END\");\n  return new TokenData(tokens);\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends ParamData = ParamData>(\n  path: Path,\n  options: CompileOptions & ParseOptions = {},\n) {\n  const { encode = encodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const data = path instanceof TokenData ? path : parse(path, options);\n  const fn = tokensToFunction(data.tokens, delimiter, encode);\n\n  return function path(data: P = {} as P) {\n    const [path, ...missing] = fn(data);\n    if (missing.length) {\n      throw new TypeError(`Missing parameters: ${missing.join(\", \")}`);\n    }\n    return path;\n  };\n}\n\nexport type ParamData = Partial<Record<string, string | string[]>>;\nexport type PathFunction<P extends ParamData> = (data?: P) => string;\n\nfunction tokensToFunction(\n  tokens: Token[],\n  delimiter: string,\n  encode: Encode | false,\n) {\n  const encoders = tokens.map((token) =>\n    tokenToFunction(token, delimiter, encode),\n  );\n\n  return (data: ParamData) => {\n    const result: string[] = [\"\"];\n\n    for (const encoder of encoders) {\n      const [value, ...extras] = encoder(data);\n      result[0] += value;\n      result.push(...extras);\n    }\n\n    return result;\n  };\n}\n\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(\n  token: Token,\n  delimiter: string,\n  encode: Encode | false,\n): (data: ParamData) => string[] {\n  if (token.type === \"text\") return () => [token.value];\n\n  if (token.type === \"group\") {\n    const fn = tokensToFunction(token.tokens, delimiter, encode);\n\n    return (data) => {\n      const [value, ...missing] = fn(data);\n      if (!missing.length) return [value];\n      return [\"\"];\n    };\n  }\n\n  const encodeValue = encode || NOOP_VALUE;\n\n  if (token.type === \"wildcard\" && encode !== false) {\n    return (data) => {\n      const value = data[token.name];\n      if (value == null) return [\"\", token.name];\n\n      if (!Array.isArray(value) || value.length === 0) {\n        throw new TypeError(`Expected \"${token.name}\" to be a non-empty array`);\n      }\n\n      return [\n        value\n          .map((value, index) => {\n            if (typeof value !== \"string\") {\n              throw new TypeError(\n                `Expected \"${token.name}/${index}\" to be a string`,\n              );\n            }\n\n            return encodeValue(value);\n          })\n          .join(delimiter),\n      ];\n    };\n  }\n\n  return (data) => {\n    const value = data[token.name];\n    if (value == null) return [\"\", token.name];\n\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n\n    return [encodeValue(value)];\n  };\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends ParamData> {\n  path: string;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends ParamData> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends ParamData> = (path: string) => Match<P>;\n\n/**\n * Supported path types.\n */\nexport type Path = string | TokenData;\n\n/**\n * Transform a path into a match function.\n */\nexport function match<P extends ParamData>(\n  path: Path | Path[],\n  options: MatchOptions & ParseOptions = {},\n): MatchFunction<P> {\n  const { decode = decodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const { regexp, keys } = pathToRegexp(path, options);\n\n  const decoders = keys.map((key) => {\n    if (decode === false) return NOOP_VALUE;\n    if (key.type === \"param\") return decode;\n    return (value: string) => value.split(delimiter).map(decode);\n  });\n\n  return function match(input: string) {\n    const m = regexp.exec(input);\n    if (!m) return false;\n\n    const path = m[0];\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n\n    return { path, params };\n  };\n}\n\nexport function pathToRegexp(\n  path: Path | Path[],\n  options: PathToRegexpOptions & ParseOptions = {},\n) {\n  const {\n    delimiter = DEFAULT_DELIMITER,\n    end = true,\n    sensitive = false,\n    trailing = true,\n  } = options;\n  const keys: Keys = [];\n  const sources: string[] = [];\n  const flags = sensitive ? \"\" : \"i\";\n  const paths = Array.isArray(path) ? path : [path];\n  const items = paths.map((path) =>\n    path instanceof TokenData ? path : parse(path, options),\n  );\n\n  for (const { tokens } of items) {\n    for (const seq of flatten(tokens, 0, [])) {\n      const regexp = sequenceToRegExp(seq, delimiter, keys);\n      sources.push(regexp);\n    }\n  }\n\n  let pattern = `^(?:${sources.join(\"|\")})`;\n  if (trailing) pattern += `(?:${escape(delimiter)}$)?`;\n  pattern += end ? \"$\" : `(?=${escape(delimiter)}|$)`;\n\n  const regexp = new RegExp(pattern, flags);\n  return { regexp, keys };\n}\n\n/**\n * Flattened token set.\n */\ntype Flattened = Text | Parameter | Wildcard;\n\n/**\n * Generate a flat list of sequence tokens from the given tokens.\n */\nfunction* flatten(\n  tokens: Token[],\n  index: number,\n  init: Flattened[],\n): Generator<Flattened[]> {\n  if (index === tokens.length) {\n    return yield init;\n  }\n\n  const token = tokens[index];\n\n  if (token.type === \"group\") {\n    const fork = init.slice();\n    for (const seq of flatten(token.tokens, 0, fork)) {\n      yield* flatten(tokens, index + 1, seq);\n    }\n  } else {\n    init.push(token);\n  }\n\n  yield* flatten(tokens, index + 1, init);\n}\n\n/**\n * Transform a flat sequence of tokens into a regular expression.\n */\nfunction sequenceToRegExp(tokens: Flattened[], delimiter: string, keys: Keys) {\n  let result = \"\";\n  let backtrack = \"\";\n  let isSafeSegmentParam = true;\n\n  for (let i = 0; i < tokens.length; i++) {\n    const token = tokens[i];\n\n    if (token.type === \"text\") {\n      result += escape(token.value);\n      backtrack += token.value;\n      isSafeSegmentParam ||= token.value.includes(delimiter);\n      continue;\n    }\n\n    if (token.type === \"param\" || token.type === \"wildcard\") {\n      if (!isSafeSegmentParam && !backtrack) {\n        throw new TypeError(`Missing text after \"${token.name}\": ${DEBUG_URL}`);\n      }\n\n      if (token.type === \"param\") {\n        result += `(${negate(delimiter, isSafeSegmentParam ? \"\" : backtrack)}+)`;\n      } else {\n        result += `([\\\\s\\\\S]+)`;\n      }\n\n      keys.push(token);\n      backtrack = \"\";\n      isSafeSegmentParam = false;\n      continue;\n    }\n  }\n\n  return result;\n}\n\nfunction negate(delimiter: string, backtrack: string) {\n  if (backtrack.length < 2) {\n    if (delimiter.length < 2) return `[^${escape(delimiter + backtrack)}]`;\n    return `(?:(?!${escape(delimiter)})[^${escape(backtrack)}])`;\n  }\n  if (delimiter.length < 2) {\n    return `(?:(?!${escape(backtrack)})[^${escape(delimiter)}])`;\n  }\n  return `(?:(?!${escape(backtrack)}|${escape(delimiter)})[\\\\s\\\\S])`;\n}\n\n/**\n * Stringify token data into a path string.\n */\nexport function stringify(data: TokenData) {\n  return data.tokens\n    .map(function stringifyToken(token, index, tokens): string {\n      if (token.type === \"text\") return escapeText(token.value);\n      if (token.type === \"group\") {\n        return `{${token.tokens.map(stringifyToken).join(\"\")}}`;\n      }\n\n      const isSafe =\n        isNameSafe(token.name) && isNextNameSafe(tokens[index + 1]);\n      const key = isSafe ? token.name : JSON.stringify(token.name);\n\n      if (token.type === \"param\") return `:${key}`;\n      if (token.type === \"wildcard\") return `*${key}`;\n      throw new TypeError(`Unexpected token: ${token}`);\n    })\n    .join(\"\");\n}\n\nfunction isNameSafe(name: string) {\n  const [first, ...rest] = name;\n  if (!ID_START.test(first)) return false;\n  return rest.every((char) => ID_CONTINUE.test(char));\n}\n\nfunction isNextNameSafe(token: Token | undefined) {\n  if (token?.type !== \"text\") return true;\n  return !ID_CONTINUE.test(token.value[0]);\n}\n","/* eslint-disable\n    @typescript-eslint/no-namespace,\n */\n\nimport {\n    type Encode as p2rEncode,\n    type Decode as p2rDecode,\n    type ParseOptions as p2rParseOptions,\n    type PathToRegexpOptions as p2rPathToRegexpOptions,\n    type MatchOptions as p2rMatchOptions,\n    type CompileOptions as p2rCompileOptions,\n    type ParamData as p2rParamData,\n    type PathFunction as p2rPathFunction,\n    type MatchResult as p2rMatchResult,\n    type Match as p2rMatch,\n    type MatchFunction as p2rMatchFunction,\n    type Key as p2rKey,\n    type Token as p2rToken,\n    type Path as p2rPath,\n    TokenData as p2rTokenData,\n    parse,\n    compile,\n    match,\n    stringify,\n    pathToRegexp,\n} from 'path-to-regexp';\n\ndeclare namespace path2regexp {\n    export type Encode = p2rEncode;\n    export type Decode = p2rDecode;\n    export type ParseOptions = p2rParseOptions;\n    export type PathToRegexpOptions = p2rPathToRegexpOptions;\n    export type MatchOptions = p2rMatchOptions;\n    export type CompileOptions = p2rCompileOptions;\n    export type TokenData = p2rTokenData;\n    export type ParamData = p2rParamData;\n    export type PathFunction<P extends ParamData> = p2rPathFunction<P>;\n    export type MatchResult<P extends ParamData> = p2rMatchResult<P>;\n    export type Match<P extends ParamData> = p2rMatch<P>;\n    export type MatchFunction<P extends ParamData> = p2rMatchFunction<P>;\n    export type Key = p2rKey;\n    export type Token = p2rToken;\n    export type Path = p2rPath;\n}\n\nconst path2regexp = {\n    TokenData: p2rTokenData,\n    parse,\n    compile,\n    match,\n    stringify,\n    pathToRegexp,\n};\n\nexport { path2regexp };\n"],"mappings":";;;;4YAoRAA,EAAAC,MA6CCA,EAKDD,EAAAE,QAAA,SAAgBA,EACdC,EACAC,EAAyC,IAEzC,MAAMC,OAAEA,EAASC,mBAAkBC,UAAEA,EAAYC,GAC/CJ,EACIK,EAAON,aAAgBO,EAAYP,EAAOF,EAAME,EAAMC,GACtDO,EAAKC,EAAiBH,EAAKI,OAAQN,EAAWF,GAEpD,OAAO,SAASF,EAAKM,EAAU,IAC7B,MAAON,KAASW,GAAWH,EAAGF,GAC9B,GAAIK,EAAQC,OACV,MAAM,IAAIC,UAAU,uBAAuBF,EAAQG,KAAK,SAE1D,OAAOd,C,CAEX,EAgHAH,EAAAkB,MAAA,SAAgBA,EACdf,EACAC,EAAuC,IAEvC,MAAMe,OAAEA,EAASC,mBAAkBb,UAAEA,EAAYC,GAC/CJ,GACIiB,OAAEA,EAAMC,KAAEA,GAASC,EAAapB,EAAMC,GAEtCoB,EAAWF,EAAKG,KAAKC,IACV,IAAXP,EAAyBQ,EACZ,UAAbD,EAAIE,KAAyBT,EACzBU,GAAkBA,EAAMC,MAAMvB,GAAWkB,IAAIN,KAGvD,OAAO,SAASD,EAAMa,GACpB,MAAMC,EAAIX,EAAOY,KAAKF,GACtB,IAAKC,EAAG,OAAO,EAEf,MAAM7B,EAAO6B,EAAE,GACTE,EAASC,OAAOC,OAAO,MAE7B,IAAK,IAAIC,EAAI,EAAGA,EAAIL,EAAEjB,OAAQsB,IAAK,CACjC,QAAaC,IAATN,EAAEK,GAAkB,SAExB,MAAMX,EAAMJ,EAAKe,EAAI,GACfE,EAAUf,EAASa,EAAI,GAC7BH,EAAOR,EAAIc,MAAQD,EAAQP,EAAEK,G,CAG/B,MAAO,CAAElC,OAAM+B,S,CAEnB,EAEAlC,EAAAuB,aA+BCA,EAsFDvB,EAAAyC,UAAA,SAAgBA,EAAUhC,GACxB,OAAOA,EAAKI,OACTY,KAAI,SAASiB,EAAeC,EAAOC,EAAO/B,GACzC,GAAmB,SAAf8B,EAAMf,KAAiB,OAxfjC,SAASiB,EAAWC,GAClB,OAAOA,EAAIC,QAAQ,mBAAoB,OACzC,CAsfwCF,CAAWF,EAAMd,OACnD,GAAmB,UAAfc,EAAMf,KACR,MAAO,IAAIe,EAAM9B,OAAOY,IAAIiB,GAAgBzB,KAAK,OAGnD,MAAM+B,EAWZ,SAASC,EAAWT,GAClB,MAAOU,KAAUC,GAAQX,EACzB,QAAKY,EAASC,KAAKH,IACZC,EAAKG,OAAOC,GAASC,EAAYH,KAAKE,IAC/C,CAdQN,CAAWN,EAAMH,OAgBzB,SAASiB,EAAed,GACtB,MAAoB,UAAhBA,aAAK,EAALA,EAAOf,QACH4B,EAAYH,KAAKV,EAAMd,MAAM,GACvC,CAnBkC4B,CAAe5C,EAAO+B,EAAQ,IACpDlB,EAAMsB,EAASL,EAAMH,KAAOkB,KAAKjB,UAAUE,EAAMH,MAEvD,GAAmB,UAAfG,EAAMf,KAAkB,MAAO,IAAIF,IACvC,GAAmB,aAAfiB,EAAMf,KAAqB,MAAO,IAAIF,IAC1C,MAAM,IAAIV,UAAU,qBAAqB2B,I,IAE1C1B,KAAK,GACV,EA7mBA,MAAMT,EAAoB,IACpBmB,EAAcE,GAAkBA,EAChCuB,EAAW,sBACXI,EAAc,oCACdG,EAAY,oCAkFZC,EAA2C,CAE/C,IAAK,IACL,IAAK,IAEL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,KAaP,SAASC,EAAOf,GACd,OAAOA,EAAIC,QAAQ,uBAAwB,OAC7C,CAoEA,MAAMe,EAGJ,WAAAC,CAAoBlD,GAAAmD,KAAMnD,OAANA,C,CAEpB,IAAAoD,GACE,IAAKD,KAAKE,MAAO,CACf,MAAMC,EAAOH,KAAKnD,OAAOsD,OACzBH,KAAKE,MAAQC,EAAKtC,K,CAEpB,OAAOmC,KAAKE,K,CAGd,UAAAE,CAAWxC,GACT,MAAMe,EAAQqB,KAAKC,OACnB,GAAItB,EAAMf,OAASA,EAEnB,OADAoC,KAAKE,WAAQ5B,EACNK,EAAMd,K,CAGf,OAAAwC,CAAQzC,GACN,MAAMC,EAAQmC,KAAKI,WAAWxC,GAC9B,QAAcU,IAAVT,EAAqB,OAAOA,EAChC,MAAQD,KAAM0C,EAAQ1B,MAAEA,GAAUoB,KAAKC,OACvC,MAAM,IAAIjD,UACR,cAAcsD,QAAe1B,eAAmBhB,MAAS+B,I,CAI7D,IAAAY,GACE,IACI1C,EADA2C,EAAS,GAEb,KAAQ3C,EAAQmC,KAAKI,WAAW,SAAWJ,KAAKI,WAAW,YACzDI,GAAU3C,EAEZ,OAAO2C,C,EAsDX,MAAa9D,EACX,WAAAqD,CAA4BlD,GAAAmD,KAAMnD,OAANA,C,EAM9B,SAAgBZ,EAAM6C,EAAa1C,EAAwB,IACzD,MAAMqE,WAAEA,EAAa9C,GAAevB,EAC9BsE,EAAK,IAAIZ,EAjKjB,SAAUa,EAAM7B,GACd,MAAM8B,EAAQ,IAAI9B,GAClB,IAAIT,EAAI,EAER,SAASG,IACP,IAAIX,EAAQ,GAEZ,GAAIuB,EAASC,KAAKuB,IAAQvC,IAExB,IADAR,GAAS+C,EAAMvC,GACRmB,EAAYH,KAAKuB,IAAQvC,KAC9BR,GAAS+C,EAAMvC,QAEZ,GAAiB,MAAbuC,EAAMvC,GAAY,CAC3B,IAAIwC,EAAMxC,EAEV,KAAOA,EAAIuC,EAAM7D,QAAQ,CACvB,GAAmB,MAAf6D,IAAQvC,GAAY,CACtBA,IACAwC,EAAM,EACN,K,CAIAhD,GADe,OAAb+C,EAAMvC,GACCuC,IAAQvC,GAERuC,EAAMvC,E,CAInB,GAAIwC,EACF,MAAM,IAAI7D,UAAU,yBAAyB6D,MAAQlB,I,CAIzD,IAAK9B,EACH,MAAM,IAAIb,UAAU,6BAA6BqB,MAAMsB,KAGzD,OAAO9B,C,CAGT,KAAOQ,EAAIuC,EAAM7D,QAAQ,CACvB,MAAMc,EAAQ+C,EAAMvC,GACdT,EAAOgC,EAAc/B,GAE3B,GAAID,OACI,CAAEA,OAAMgB,MAAOP,IAAKR,cACrB,GAAc,OAAVA,OACH,CAAED,KAAM,UAAWgB,MAAOP,IAAKR,MAAO+C,EAAMvC,WAC7C,GAAc,MAAVR,EAAe,CACxB,MAAMA,EAAQW,SACR,CAAEZ,KAAM,QAASgB,MAAOP,EAAGR,Q,MAC5B,GAAc,MAAVA,EAAe,CACxB,MAAMA,EAAQW,SACR,CAAEZ,KAAM,WAAYgB,MAAOP,EAAGR,Q,WAE9B,CAAED,KAAM,OAAQgB,MAAOP,EAAGR,MAAO+C,EAAMvC,K,CAIjD,MAAO,CAAET,KAAM,MAAOgB,MAAOP,EAAGR,MAAO,GACzC,CAoGsB8C,CAAM7B,IAyC1B,MAAMjC,EAvCN,SAASwD,EAAQS,GACf,MAAMjE,EAAkB,GAExB,OAAa,CACX,MAAMV,EAAOuE,EAAGH,OACZpE,GAAMU,EAAOkE,KAAK,CAAEnD,KAAM,OAAQC,MAAO4C,EAAWtE,KAExD,MAAM6E,EAAQN,EAAGN,WAAW,SAC5B,GAAIY,EAAO,CACTnE,EAAOkE,KAAK,CACVnD,KAAM,QACNY,KAAMwC,IAER,Q,CAGF,MAAMC,EAAWP,EAAGN,WAAW,YAC/B,GAAIa,EAAU,CACZpE,EAAOkE,KAAK,CACVnD,KAAM,WACNY,KAAMyC,IAER,Q,CAGF,MAAMC,EAAOR,EAAGN,WAAW,KAC3B,IAAIc,EASJ,OADAR,EAAGL,QAAQS,GACJjE,EARLA,EAAOkE,KAAK,CACVnD,KAAM,QACNf,OAAQwD,EAAQ,M,EAUTA,CAAQ,OACvB,OAAO,IAAI3D,EAAUG,EACvB,CA0BA,SAASD,EACPC,EACAN,EACAF,GAEA,MAAM8E,EAAWtE,EAAOY,KAAKkB,GAoB/B,SAASyC,EACPzC,EACApC,EACAF,GAEA,GAAmB,SAAfsC,EAAMf,KAAiB,MAAO,IAAM,CAACe,EAAMd,OAE/C,GAAmB,UAAfc,EAAMf,KAAkB,CAC1B,MAAMjB,EAAKC,EAAiB+B,EAAM9B,OAAQN,EAAWF,GAErD,OAAQI,IACN,MAAOoB,KAAUf,GAAWH,EAAGF,GAC/B,OAAKK,EAAQC,OACN,CAAC,IADoB,CAACc,G,CAKjC,MAAMwD,EAAchF,GAAUsB,EAE9B,GAAmB,aAAfgB,EAAMf,OAAkC,IAAXvB,EAC/B,OAAQI,IACN,MAAMoB,EAAQpB,EAAKkC,EAAMH,MACzB,GAAa,MAATX,EAAe,MAAO,CAAC,GAAIc,EAAMH,MAErC,IAAK8C,MAAMC,QAAQ1D,IAA2B,IAAjBA,EAAMd,OACjC,MAAM,IAAIC,UAAU,aAAa2B,EAAMH,iCAGzC,MAAO,CACLX,EACGJ,KAAI,CAACI,EAAOe,KACX,GAAqB,iBAAVf,EACT,MAAM,IAAIb,UACR,aAAa2B,EAAMH,QAAQI,qBAI/B,OAAOyC,EAAYxD,MAEpBZ,KAAKV,KAKd,OAAQE,IACN,MAAMoB,EAAQpB,EAAKkC,EAAMH,MACzB,GAAa,MAATX,EAAe,MAAO,CAAC,GAAIc,EAAMH,MAErC,GAAqB,iBAAVX,EACT,MAAM,IAAIb,UAAU,aAAa2B,EAAMH,wBAGzC,MAAO,CAAC6C,EAAYxD,IAExB,CAzEIuD,CAAgBzC,EAAOpC,EAAWF,KAGpC,OAAQI,IACN,MAAM+D,EAAmB,CAAC,IAE1B,IAAK,MAAMgB,KAAWL,EAAU,CAC9B,MAAOtD,KAAU4D,GAAUD,EAAQ/E,GACnC+D,EAAO,IAAM3C,EACb2C,EAAOO,QAAQU,E,CAGjB,OAAOjB,EAEX,CAwHA,SAAgBjD,EACdpB,EACAC,EAA8C,IAE9C,MAAMG,UACJA,EAAYC,EAAiBkF,IAC7BA,GAAM,EAAIC,UACVA,GAAY,EAAKC,SACjBA,GAAW,GACTxF,EACEkB,EAAa,GACbuE,EAAoB,GACpBC,EAAQH,EAAY,GAAK,IACzBI,EAAQT,MAAMC,QAAQpF,GAAQA,EAAO,CAACA,GACtC6F,EAAQD,EAAMtE,KAAKtB,GACvBA,aAAgBO,EAAYP,EAAOF,EAAME,EAAMC,KAGjD,IAAK,MAAMS,OAAEA,KAAYmF,EACvB,IAAK,MAAMC,KAAOC,EAAQrF,EAAQ,EAAG,IAAK,CACxC,MAAMQ,EAAS8E,EAAiBF,EAAK1F,EAAWe,GAChDuE,EAAQd,KAAK1D,E,CAIjB,IAAI+E,EAAU,OAAOP,EAAQ5E,KAAK,QAC9B2E,IAAUQ,GAAW,MAAMvC,EAAOtD,SACtC6F,GAAWV,EAAM,IAAM,MAAM7B,EAAOtD,QAEpC,MAAMc,EAAS,IAAIgF,OAAOD,EAASN,GACnC,MAAO,CAAEzE,SAAQC,OACnB,CAUA,SAAU4E,EACRrF,EACA+B,EACA0D,GAEA,GAAI1D,IAAU/B,EAAOE,OACnB,aAAauF,EAGf,MAAM3D,EAAQ9B,EAAO+B,GAErB,GAAmB,UAAfD,EAAMf,KAAkB,CAC1B,MAAM2E,EAAOD,EAAKE,QAClB,IAAK,MAAMP,KAAOC,EAAQvD,EAAM9B,OAAQ,EAAG0F,SAClCL,EAAQrF,EAAQ+B,EAAQ,EAAGqD,E,MAGpCK,EAAKvB,KAAKpC,SAGLuD,EAAQrF,EAAQ+B,EAAQ,EAAG0D,EACpC,CAKA,SAASH,EAAiBtF,EAAqBN,EAAmBe,GAChE,IAAIkD,EAAS,GACTiC,EAAY,GACZC,GAAqB,EAEzB,IAAK,IAAIrE,EAAI,EAAGA,EAAIxB,EAAOE,OAAQsB,IAAK,CACtC,MAAMM,EAAQ9B,EAAOwB,GAErB,GAAmB,SAAfM,EAAMf,KAOV,GAAmB,UAAfe,EAAMf,MAAmC,aAAfe,EAAMf,UAApC,CACE,IAAK8E,IAAuBD,EAC1B,MAAM,IAAIzF,UAAU,uBAAuB2B,EAAMH,UAAUmB,KAG1C,UAAfhB,EAAMf,KACR4C,GAAU,IAAImC,EAAOpG,EAAWmG,EAAqB,GAAKD,OAE1DjC,GAAU,cAGZlD,EAAKyD,KAAKpC,GACV8D,EAAY,GACZC,GAAqB,C,MAnBrBlC,GAAUX,EAAOlB,EAAMd,OACvB4E,GAAa9D,EAAMd,MACnB6E,MAAuB/D,EAAMd,MAAM+E,SAASrG,G,CAsBhD,OAAOiE,CACT,CAEA,SAASmC,EAAOpG,EAAmBkG,GACjC,OAAIA,EAAU1F,OAAS,EACjBR,EAAUQ,OAAS,EAAU,KAAK8C,EAAOtD,EAAYkG,MAClD,SAAS5C,EAAOtD,QAAgBsD,EAAO4C,OAE5ClG,EAAUQ,OAAS,EACd,SAAS8C,EAAO4C,QAAgB5C,EAAOtD,OAEzC,SAASsD,EAAO4C,MAAc5C,EAAOtD,cAC9C,C,OA1UAP,EAAAU,UAECA,E,KClOD,MAAMmG,EAAc,CAChBnG,UAAWoG,Y,MACX7G,Q,QACAC,U,MACAgB,Q,UACAuB,Y,aACAlB,gB","ignoreList":[]}
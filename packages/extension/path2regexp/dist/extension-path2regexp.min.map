{"version":3,"names":["dist","parse","compile","path","options","encode","encodeURIComponent","delimiter","DEFAULT_DELIMITER","data","fn","tokensToFunction","tokens","params","missing","length","TypeError","join","match","decode","decodeURIComponent","regexp","keys","pathToRegexp","decoders","map","key","NOOP_VALUE","type","value","split","input","m","exec","Object","create","i","undefined","decoder","name","stringify","stringifyTokens","ID_START","ID_CONTINUE","SIMPLE_TOKENS","escapeText","str","replace","escape","TokenData","constructor","originalPath","this","PathError","message","text","super","encodePath","chars","index","pos","test","quoteStart","push","consumeUntil","endType","output","token","cur","encoders","tokenToFunction","encodeValue","Array","isArray","result","encoder","extras","end","sensitive","trailing","flags","sources","pathsToArray","flatten","toRegExpSource","pattern","RegExp","paths","init","p","seq","slice","backtrack","isSafeSegmentParam","negate","includes","isSafe","isNameSafe","first","rest","every","char","isNextNameSafe","JSON","path2regexp","p2rTokenData","p2rPathError"],"sources":["cdp:///@cdp/extension-path2regexp/path-to-regexp/src/index.ts","cdp:///@cdp/extension-path2regexp/index.ts"],"sourcesContent":["const DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = (value: string) => value;\nconst ID_START = /^[$_\\p{ID_Start}]$/u;\nconst ID_CONTINUE = /^[$\\u200c\\u200d\\p{ID_Continue}]$/u;\n\n/**\n * Encode a string into another string.\n */\nexport type Encode = (value: string) => string;\n\n/**\n * Decode a string into another string.\n */\nexport type Decode = (value: string) => string;\n\nexport interface ParseOptions {\n  /**\n   * A function for encoding input strings.\n   */\n  encodePath?: Encode;\n}\n\nexport interface PathToRegexpOptions {\n  /**\n   * Matches the path completely without trailing characters. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * Allows optional trailing delimiter to match. (default: `true`)\n   */\n  trailing?: boolean;\n  /**\n   * Match will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\nexport interface MatchOptions extends PathToRegexpOptions {\n  /**\n   * Function for decoding strings for params, or `false` to disable entirely. (default: `decodeURIComponent`)\n   */\n  decode?: Decode | false;\n}\n\nexport interface CompileOptions {\n  /**\n   * Function for encoding input strings for output into the path, or `false` to disable entirely. (default: `encodeURIComponent`)\n   */\n  encode?: Encode | false;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\ntype TokenType =\n  | \"{\"\n  | \"}\"\n  | \"wildcard\"\n  | \"param\"\n  | \"char\"\n  | \"escape\"\n  | \"end\"\n  // Reserved for use or ambiguous due to past use.\n  | \"(\"\n  | \")\"\n  | \"[\"\n  | \"]\"\n  | \"+\"\n  | \"?\"\n  | \"!\";\n\n/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type: TokenType;\n  index: number;\n  value: string;\n}\n\nconst SIMPLE_TOKENS: Record<string, TokenType> = {\n  // Groups.\n  \"{\": \"{\",\n  \"}\": \"}\",\n  // Reserved.\n  \"(\": \"(\",\n  \")\": \")\",\n  \"[\": \"[\",\n  \"]\": \"]\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"!\": \"!\",\n};\n\n/**\n * Escape text for stringify to path.\n */\nfunction escapeText(str: string) {\n  return str.replace(/[{}()\\[\\]+?!:*\\\\]/g, \"\\\\$&\");\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escape(str: string) {\n  return str.replace(/[.+*?^${}()[\\]|/\\\\]/g, \"\\\\$&\");\n}\n\n/**\n * Plain text.\n */\nexport interface Text {\n  type: \"text\";\n  value: string;\n}\n\n/**\n * A parameter designed to match arbitrary text within a segment.\n */\nexport interface Parameter {\n  type: \"param\";\n  name: string;\n}\n\n/**\n * A wildcard parameter designed to match multiple segments.\n */\nexport interface Wildcard {\n  type: \"wildcard\";\n  name: string;\n}\n\n/**\n * A set of possible tokens to expand when matching.\n */\nexport interface Group {\n  type: \"group\";\n  tokens: Token[];\n}\n\n/**\n * A token that corresponds with a regexp capture.\n */\nexport type Key = Parameter | Wildcard;\n\n/**\n * A sequence of `path-to-regexp` keys that match capturing groups.\n */\nexport type Keys = Array<Key>;\n\n/**\n * A sequence of path match characters.\n */\nexport type Token = Text | Parameter | Wildcard | Group;\n\n/**\n * Tokenized path instance.\n */\nexport class TokenData {\n  constructor(\n    public readonly tokens: Token[],\n    public readonly originalPath?: string,\n  ) {}\n}\n\n/**\n * ParseError is thrown when there is an error processing the path.\n */\nexport class PathError extends TypeError {\n  constructor(\n    message: string,\n    public readonly originalPath: string | undefined,\n  ) {\n    let text = message;\n    if (originalPath) text += `: ${originalPath}`;\n    text += `; visit https://git.new/pathToRegexpError for info`;\n    super(text);\n  }\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): TokenData {\n  const { encodePath = NOOP_VALUE } = options;\n  const chars = [...str];\n  const tokens: Array<LexToken> = [];\n  let index = 0;\n  let pos = 0;\n\n  function name() {\n    let value = \"\";\n\n    if (ID_START.test(chars[index])) {\n      do {\n        value += chars[index++];\n      } while (ID_CONTINUE.test(chars[index]));\n    } else if (chars[index] === '\"') {\n      let quoteStart = index;\n\n      while (index++ < chars.length) {\n        if (chars[index] === '\"') {\n          index++;\n          quoteStart = 0;\n          break;\n        }\n\n        // Increment over escape characters.\n        if (chars[index] === \"\\\\\") index++;\n\n        value += chars[index];\n      }\n\n      if (quoteStart) {\n        throw new PathError(`Unterminated quote at index ${quoteStart}`, str);\n      }\n    }\n\n    if (!value) {\n      throw new PathError(`Missing parameter name at index ${index}`, str);\n    }\n\n    return value;\n  }\n\n  while (index < chars.length) {\n    const value = chars[index];\n    const type = SIMPLE_TOKENS[value];\n\n    if (type) {\n      tokens.push({ type, index: index++, value });\n    } else if (value === \"\\\\\") {\n      tokens.push({ type: \"escape\", index: index++, value: chars[index++] });\n    } else if (value === \":\") {\n      tokens.push({ type: \"param\", index: index++, value: name() });\n    } else if (value === \"*\") {\n      tokens.push({ type: \"wildcard\", index: index++, value: name() });\n    } else {\n      tokens.push({ type: \"char\", index: index++, value });\n    }\n  }\n\n  tokens.push({ type: \"end\", index, value: \"\" });\n\n  function consumeUntil(endType: TokenType): Token[] {\n    const output: Token[] = [];\n\n    while (true) {\n      const token = tokens[pos++];\n      if (token.type === endType) break;\n\n      if (token.type === \"char\" || token.type === \"escape\") {\n        let path = token.value;\n        let cur = tokens[pos];\n\n        while (cur.type === \"char\" || cur.type === \"escape\") {\n          path += cur.value;\n          cur = tokens[++pos];\n        }\n\n        output.push({\n          type: \"text\",\n          value: encodePath(path),\n        });\n        continue;\n      }\n\n      if (token.type === \"param\" || token.type === \"wildcard\") {\n        output.push({\n          type: token.type,\n          name: token.value,\n        });\n        continue;\n      }\n\n      if (token.type === \"{\") {\n        output.push({\n          type: \"group\",\n          tokens: consumeUntil(\"}\"),\n        });\n        continue;\n      }\n\n      throw new PathError(\n        `Unexpected ${token.type} at index ${token.index}, expected ${endType}`,\n        str,\n      );\n    }\n\n    return output;\n  }\n\n  return new TokenData(consumeUntil(\"end\"), str);\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends ParamData = ParamData>(\n  path: Path,\n  options: CompileOptions & ParseOptions = {},\n) {\n  const { encode = encodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const data = typeof path === \"object\" ? path : parse(path, options);\n  const fn = tokensToFunction(data.tokens, delimiter, encode);\n\n  return function path(params: P = {} as P) {\n    const [path, ...missing] = fn(params);\n    if (missing.length) {\n      throw new TypeError(`Missing parameters: ${missing.join(\", \")}`);\n    }\n    return path;\n  };\n}\n\nexport type ParamData = Partial<Record<string, string | string[]>>;\nexport type PathFunction<P extends ParamData> = (data?: P) => string;\n\nfunction tokensToFunction(\n  tokens: Token[],\n  delimiter: string,\n  encode: Encode | false,\n) {\n  const encoders = tokens.map((token) =>\n    tokenToFunction(token, delimiter, encode),\n  );\n\n  return (data: ParamData) => {\n    const result: string[] = [\"\"];\n\n    for (const encoder of encoders) {\n      const [value, ...extras] = encoder(data);\n      result[0] += value;\n      result.push(...extras);\n    }\n\n    return result;\n  };\n}\n\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(\n  token: Token,\n  delimiter: string,\n  encode: Encode | false,\n): (data: ParamData) => string[] {\n  if (token.type === \"text\") return () => [token.value];\n\n  if (token.type === \"group\") {\n    const fn = tokensToFunction(token.tokens, delimiter, encode);\n\n    return (data) => {\n      const [value, ...missing] = fn(data);\n      if (!missing.length) return [value];\n      return [\"\"];\n    };\n  }\n\n  const encodeValue = encode || NOOP_VALUE;\n\n  if (token.type === \"wildcard\" && encode !== false) {\n    return (data) => {\n      const value = data[token.name];\n      if (value == null) return [\"\", token.name];\n\n      if (!Array.isArray(value) || value.length === 0) {\n        throw new TypeError(`Expected \"${token.name}\" to be a non-empty array`);\n      }\n\n      return [\n        value\n          .map((value, index) => {\n            if (typeof value !== \"string\") {\n              throw new TypeError(\n                `Expected \"${token.name}/${index}\" to be a string`,\n              );\n            }\n\n            return encodeValue(value);\n          })\n          .join(delimiter),\n      ];\n    };\n  }\n\n  return (data) => {\n    const value = data[token.name];\n    if (value == null) return [\"\", token.name];\n\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n\n    return [encodeValue(value)];\n  };\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends ParamData> {\n  path: string;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends ParamData> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends ParamData> = (path: string) => Match<P>;\n\n/**\n * Supported path types.\n */\nexport type Path = string | TokenData;\n\n/**\n * Transform a path into a match function.\n */\nexport function match<P extends ParamData>(\n  path: Path | Path[],\n  options: MatchOptions & ParseOptions = {},\n): MatchFunction<P> {\n  const { decode = decodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const { regexp, keys } = pathToRegexp(path, options);\n\n  const decoders = keys.map((key) => {\n    if (decode === false) return NOOP_VALUE;\n    if (key.type === \"param\") return decode;\n    return (value: string) => value.split(delimiter).map(decode);\n  });\n\n  return function match(input: string) {\n    const m = regexp.exec(input);\n    if (!m) return false;\n\n    const path = m[0];\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n\n    return { path, params };\n  };\n}\n\nexport function pathToRegexp(\n  path: Path | Path[],\n  options: PathToRegexpOptions & ParseOptions = {},\n) {\n  const {\n    delimiter = DEFAULT_DELIMITER,\n    end = true,\n    sensitive = false,\n    trailing = true,\n  } = options;\n  const keys: Keys = [];\n  const flags = sensitive ? \"\" : \"i\";\n  const sources: string[] = [];\n\n  for (const input of pathsToArray(path, [])) {\n    const data = typeof input === \"object\" ? input : parse(input, options);\n    for (const tokens of flatten(data.tokens, 0, [])) {\n      sources.push(toRegExpSource(tokens, delimiter, keys, data.originalPath));\n    }\n  }\n\n  let pattern = `^(?:${sources.join(\"|\")})`;\n  if (trailing) pattern += `(?:${escape(delimiter)}$)?`;\n  pattern += end ? \"$\" : `(?=${escape(delimiter)}|$)`;\n\n  const regexp = new RegExp(pattern, flags);\n  return { regexp, keys };\n}\n\n/**\n * Convert a path or array of paths into a flat array.\n */\nfunction pathsToArray(paths: Path | Path[], init: Path[]): Path[] {\n  if (Array.isArray(paths)) {\n    for (const p of paths) pathsToArray(p, init);\n  } else {\n    init.push(paths);\n  }\n  return init;\n}\n\n/**\n * Flattened token set.\n */\ntype FlatToken = Text | Parameter | Wildcard;\n\n/**\n * Generate a flat list of sequence tokens from the given tokens.\n */\nfunction* flatten(\n  tokens: Token[],\n  index: number,\n  init: FlatToken[],\n): Generator<FlatToken[]> {\n  if (index === tokens.length) {\n    return yield init;\n  }\n\n  const token = tokens[index];\n\n  if (token.type === \"group\") {\n    for (const seq of flatten(token.tokens, 0, init.slice())) {\n      yield* flatten(tokens, index + 1, seq);\n    }\n  } else {\n    init.push(token);\n  }\n\n  yield* flatten(tokens, index + 1, init);\n}\n\n/**\n * Transform a flat sequence of tokens into a regular expression.\n */\nfunction toRegExpSource(\n  tokens: FlatToken[],\n  delimiter: string,\n  keys: Keys,\n  originalPath: string | undefined,\n): string {\n  let result = \"\";\n  let backtrack = \"\";\n  let isSafeSegmentParam = true;\n\n  for (const token of tokens) {\n    if (token.type === \"text\") {\n      result += escape(token.value);\n      backtrack += token.value;\n      isSafeSegmentParam ||= token.value.includes(delimiter);\n      continue;\n    }\n\n    if (token.type === \"param\" || token.type === \"wildcard\") {\n      if (!isSafeSegmentParam && !backtrack) {\n        throw new PathError(\n          `Missing text before \"${token.name}\" ${token.type}`,\n          originalPath,\n        );\n      }\n\n      if (token.type === \"param\") {\n        result += `(${negate(delimiter, isSafeSegmentParam ? \"\" : backtrack)}+)`;\n      } else {\n        result += `([\\\\s\\\\S]+)`;\n      }\n\n      keys.push(token);\n      backtrack = \"\";\n      isSafeSegmentParam = false;\n      continue;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Block backtracking on previous text and ignore delimiter string.\n */\nfunction negate(delimiter: string, backtrack: string): string {\n  if (backtrack.length < 2) {\n    if (delimiter.length < 2) return `[^${escape(delimiter + backtrack)}]`;\n    return `(?:(?!${escape(delimiter)})[^${escape(backtrack)}])`;\n  }\n  if (delimiter.length < 2) {\n    return `(?:(?!${escape(backtrack)})[^${escape(delimiter)}])`;\n  }\n  return `(?:(?!${escape(backtrack)}|${escape(delimiter)})[\\\\s\\\\S])`;\n}\n\n/**\n * Stringify an array of tokens into a path string.\n */\nfunction stringifyTokens(tokens: Token[]): string {\n  let value = \"\";\n  let i = 0;\n\n  function name(value: string) {\n    const isSafe = isNameSafe(value) && isNextNameSafe(tokens[i]);\n    return isSafe ? value : JSON.stringify(value);\n  }\n\n  while (i < tokens.length) {\n    const token = tokens[i++];\n\n    if (token.type === \"text\") {\n      value += escapeText(token.value);\n      continue;\n    }\n\n    if (token.type === \"group\") {\n      value += `{${stringifyTokens(token.tokens)}}`;\n      continue;\n    }\n\n    if (token.type === \"param\") {\n      value += `:${name(token.name)}`;\n      continue;\n    }\n\n    if (token.type === \"wildcard\") {\n      value += `*${name(token.name)}`;\n      continue;\n    }\n\n    throw new TypeError(`Unknown token type: ${(token as any).type}`);\n  }\n\n  return value;\n}\n\n/**\n * Stringify token data into a path string.\n */\nexport function stringify(data: TokenData): string {\n  return stringifyTokens(data.tokens);\n}\n\n/**\n * Validate the parameter name contains valid ID characters.\n */\nfunction isNameSafe(name: string): boolean {\n  const [first, ...rest] = name;\n  return ID_START.test(first) && rest.every((char) => ID_CONTINUE.test(char));\n}\n\n/**\n * Validate the next token does not interfere with the current param name.\n */\nfunction isNextNameSafe(token: Token | undefined): boolean {\n  if (token && token.type === \"text\") return !ID_CONTINUE.test(token.value[0]);\n  return true;\n}\n","/* eslint-disable\n    @typescript-eslint/no-namespace,\n */\n\nimport {\n    type Encode as p2rEncode,\n    type Decode as p2rDecode,\n    type ParseOptions as p2rParseOptions,\n    type PathToRegexpOptions as p2rPathToRegexpOptions,\n    type MatchOptions as p2rMatchOptions,\n    type CompileOptions as p2rCompileOptions,\n    type ParamData as p2rParamData,\n    type PathFunction as p2rPathFunction,\n    type MatchResult as p2rMatchResult,\n    type Match as p2rMatch,\n    type MatchFunction as p2rMatchFunction,\n    type Key as p2rKey,\n    type Token as p2rToken,\n    type Path as p2rPath,\n    TokenData as p2rTokenData,\n    PathError as p2rPathError,\n    parse,\n    compile,\n    match,\n    stringify,\n    pathToRegexp,\n} from 'path-to-regexp';\n\ndeclare namespace path2regexp {\n    export type Encode = p2rEncode;\n    export type Decode = p2rDecode;\n    export type ParseOptions = p2rParseOptions;\n    export type PathToRegexpOptions = p2rPathToRegexpOptions;\n    export type MatchOptions = p2rMatchOptions;\n    export type CompileOptions = p2rCompileOptions;\n    export type TokenData = p2rTokenData;\n    export type ParamData = p2rParamData;\n    export type PathFunction<P extends ParamData> = p2rPathFunction<P>;\n    export type MatchResult<P extends ParamData> = p2rMatchResult<P>;\n    export type Match<P extends ParamData> = p2rMatch<P>;\n    export type MatchFunction<P extends ParamData> = p2rMatchFunction<P>;\n    export type Key = p2rKey;\n    export type Token = p2rToken;\n    export type Path = p2rPath;\n}\n\nconst path2regexp = {\n    TokenData: p2rTokenData,\n    PathError: p2rPathError,\n    parse,\n    compile,\n    match,\n    stringify,\n    pathToRegexp,\n};\n\nexport { path2regexp };\n"],"mappings":";;;;uZA4LAA,EAAAC,QAmHAD,EAAAE,QAAA,SAAgBA,EACdC,EACAC,EAAyC,IAEzC,MAAMC,OAAEA,EAASC,mBAAkBC,UAAEA,EAAYC,GAC/CJ,EACIK,EAAuB,iBAATN,EAAoBA,EAAOF,EAAME,EAAMC,GACrDM,EAAKC,EAAiBF,EAAKG,OAAQL,EAAWF,GAEpD,OAAO,SAASF,EAAKU,EAAY,IAC/B,MAAOV,KAASW,GAAWJ,EAAGG,GAC9B,GAAIC,EAAQC,OACV,MAAM,IAAIC,UAAU,uBAAuBF,EAAQG,KAAK,SAE1D,OAAOd,CACT,CACF,EAgHAH,EAAAkB,MAAA,SAAgBA,EACdf,EACAC,EAAuC,IAEvC,MAAMe,OAAEA,EAASC,mBAAkBb,UAAEA,EAAYC,GAC/CJ,GACIiB,OAAEA,EAAMC,KAAEA,GAASC,EAAapB,EAAMC,GAEtCoB,EAAWF,EAAKG,IAAKC,IACV,IAAXP,EAAyBQ,EACZ,UAAbD,EAAIE,KAAyBT,EACzBU,GAAkBA,EAAMC,MAAMvB,GAAWkB,IAAIN,IAGvD,OAAO,SAASD,EAAMa,GACpB,MAAMC,EAAIX,EAAOY,KAAKF,GACtB,IAAKC,EAAG,OAAO,EAEf,MAAM7B,EAAO6B,EAAE,GACTnB,EAASqB,OAAOC,OAAO,MAE7B,IAAK,IAAIC,EAAI,EAAGA,EAAIJ,EAAEjB,OAAQqB,IAAK,CACjC,QAAaC,IAATL,EAAEI,GAAkB,SAExB,MAAMV,EAAMJ,EAAKc,EAAI,GACfE,EAAUd,EAASY,EAAI,GAC7BvB,EAAOa,EAAIa,MAAQD,EAAQN,EAAEI,G,CAG/B,MAAO,CAAEjC,OAAMU,SACjB,CACF,EAEAb,EAAAuB,eA8KAvB,EAAAwC,UAAA,SAAgBA,EAAU/B,GACxB,OAAOgC,EAAgBhC,EAAKG,OAC9B,EAhoBA,MAAMJ,EAAoB,IACpBmB,EAAcE,GAAkBA,EAChCa,EAAW,sBACXC,EAAc,oCAkFdC,EAA2C,CAE/C,IAAK,IACL,IAAK,IAEL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,KAMP,SAASC,EAAWC,GAClB,OAAOA,EAAIC,QAAQ,qBAAsB,OAC3C,CAKA,SAASC,EAAOF,GACd,OAAOA,EAAIC,QAAQ,uBAAwB,OAC7C,CAoDA,MAAaE,EACX,WAAAC,CACkBtC,EACAuC,GADAC,KAAAxC,SACAwC,KAAAD,c,EAHpBnD,EAAAiD,YAUA,MAAaI,UAAkBrC,UAC7B,WAAAkC,CACEI,EACgBH,GAEhB,IAAII,EAAOD,EACPH,IAAcI,GAAQ,KAAKJ,KAC/BI,GAAQ,qDACRC,MAAMD,GALUH,KAAAD,c,EAYpB,SAAgBlD,EAAM6C,EAAa1C,EAAwB,IACzD,MAAMqD,WAAEA,EAAa9B,GAAevB,EAC9BsD,EAAQ,IAAIZ,GACZlC,EAA0B,GAChC,IAAI+C,EAAQ,EACRC,EAAM,EAEV,SAASrB,IACP,IAAIV,EAAQ,GAEZ,GAAIa,EAASmB,KAAKH,EAAMC,IACtB,GACE9B,GAAS6B,EAAMC,WACRhB,EAAYkB,KAAKH,EAAMC,UAC3B,GAAqB,MAAjBD,EAAMC,GAAgB,CAC/B,IAAIG,EAAaH,EAEjB,KAAOA,IAAUD,EAAM3C,QAAQ,CAC7B,GAAqB,MAAjB2C,EAAMC,GAAgB,CACxBA,IACAG,EAAa,EACb,K,CAImB,OAAjBJ,EAAMC,IAAiBA,IAE3B9B,GAAS6B,EAAMC,E,CAGjB,GAAIG,EACF,MAAM,IAAIT,EAAU,+BAA+BS,IAAchB,E,CAIrE,IAAKjB,EACH,MAAM,IAAIwB,EAAU,mCAAmCM,IAASb,GAGlE,OAAOjB,C,CAGT,KAAO8B,EAAQD,EAAM3C,QAAQ,CAC3B,MAAMc,EAAQ6B,EAAMC,GACd/B,EAAOgB,EAAcf,GAEvBD,EACFhB,EAAOmD,KAAK,CAAEnC,OAAM+B,MAAOA,IAAS9B,UACjB,OAAVA,EACTjB,EAAOmD,KAAK,CAAEnC,KAAM,SAAU+B,MAAOA,IAAS9B,MAAO6B,EAAMC,OACxC,MAAV9B,EACTjB,EAAOmD,KAAK,CAAEnC,KAAM,QAAS+B,MAAOA,IAAS9B,MAAOU,MACjC,MAAVV,EACTjB,EAAOmD,KAAK,CAAEnC,KAAM,WAAY+B,MAAOA,IAAS9B,MAAOU,MAEvD3B,EAAOmD,KAAK,CAAEnC,KAAM,OAAQ+B,MAAOA,IAAS9B,S,CAsDhD,OAlDAjB,EAAOmD,KAAK,CAAEnC,KAAM,MAAO+B,QAAO9B,MAAO,KAkDlC,IAAIoB,EAhDX,SAASe,EAAaC,GACpB,MAAMC,EAAkB,GAExB,OAAa,CACX,MAAMC,EAAQvD,EAAOgD,KACrB,GAAIO,EAAMvC,OAASqC,EAAS,MAE5B,GAAmB,SAAfE,EAAMvC,MAAkC,WAAfuC,EAAMvC,KAAmB,CACpD,IAAIzB,EAAOgE,EAAMtC,MACbuC,EAAMxD,EAAOgD,GAEjB,KAAoB,SAAbQ,EAAIxC,MAAgC,WAAbwC,EAAIxC,MAChCzB,GAAQiE,EAAIvC,MACZuC,EAAMxD,IAASgD,GAGjBM,EAAOH,KAAK,CACVnC,KAAM,OACNC,MAAO4B,EAAWtD,KAEpB,Q,CAGF,GAAmB,UAAfgE,EAAMvC,MAAmC,aAAfuC,EAAMvC,KAApC,CAQA,GAAmB,MAAfuC,EAAMvC,KAQV,MAAM,IAAIyB,EACR,cAAcc,EAAMvC,iBAAiBuC,EAAMR,mBAAmBM,IAC9DnB,GATAoB,EAAOH,KAAK,CACVnC,KAAM,QACNhB,OAAQoD,EAAa,M,MAVvBE,EAAOH,KAAK,CACVnC,KAAMuC,EAAMvC,KACZW,KAAM4B,EAAMtC,O,CAmBlB,OAAOqC,C,CAGYF,CAAa,OAAQlB,EAC5C,CA0BA,SAASnC,EACPC,EACAL,EACAF,GAEA,MAAMgE,EAAWzD,EAAOa,IAAK0C,GAoB/B,SAASG,EACPH,EACA5D,EACAF,GAEA,GAAmB,SAAf8D,EAAMvC,KAAiB,MAAO,IAAM,CAACuC,EAAMtC,OAE/C,GAAmB,UAAfsC,EAAMvC,KAAkB,CAC1B,MAAMlB,EAAKC,EAAiBwD,EAAMvD,OAAQL,EAAWF,GAErD,OAAQI,IACN,MAAOoB,KAAUf,GAAWJ,EAAGD,GAC/B,OAAKK,EAAQC,OACN,CAAC,IADoB,CAACc,G,CAKjC,MAAM0C,EAAclE,GAAUsB,EAE9B,GAAmB,aAAfwC,EAAMvC,OAAkC,IAAXvB,EAC/B,OAAQI,IACN,MAAMoB,EAAQpB,EAAK0D,EAAM5B,MACzB,GAAa,MAATV,EAAe,MAAO,CAAC,GAAIsC,EAAM5B,MAErC,IAAKiC,MAAMC,QAAQ5C,IAA2B,IAAjBA,EAAMd,OACjC,MAAM,IAAIC,UAAU,aAAamD,EAAM5B,iCAGzC,MAAO,CACLV,EACGJ,IAAI,CAACI,EAAO8B,KACX,GAAqB,iBAAV9B,EACT,MAAM,IAAIb,UACR,aAAamD,EAAM5B,QAAQoB,qBAI/B,OAAOY,EAAY1C,KAEpBZ,KAAKV,KAKd,OAAQE,IACN,MAAMoB,EAAQpB,EAAK0D,EAAM5B,MACzB,GAAa,MAATV,EAAe,MAAO,CAAC,GAAIsC,EAAM5B,MAErC,GAAqB,iBAAVV,EACT,MAAM,IAAIb,UAAU,aAAamD,EAAM5B,wBAGzC,MAAO,CAACgC,EAAY1C,IAExB,CAzEIyC,CAAgBH,EAAO5D,EAAWF,IAGpC,OAAQI,IACN,MAAMiE,EAAmB,CAAC,IAE1B,IAAK,MAAMC,KAAWN,EAAU,CAC9B,MAAOxC,KAAU+C,GAAUD,EAAQlE,GACnCiE,EAAO,IAAM7C,EACb6C,EAAOX,QAAQa,E,CAGjB,OAAOF,EAEX,CAwHA,SAAgBnD,EACdpB,EACAC,EAA8C,IAE9C,MAAMG,UACJA,EAAYC,EAAiBqE,IAC7BA,GAAM,EAAIC,UACVA,GAAY,EAAKC,SACjBA,GAAW,GACT3E,EACEkB,EAAa,GACb0D,EAAQF,EAAY,GAAK,IACzBG,EAAoB,GAE1B,IAAK,MAAMlD,KAASmD,EAAa/E,EAAM,IAAK,CAC1C,MAAMM,EAAwB,iBAAVsB,EAAqBA,EAAQ9B,EAAM8B,EAAO3B,GAC9D,IAAK,MAAMQ,KAAUuE,EAAQ1E,EAAKG,OAAQ,EAAG,IAC3CqE,EAAQlB,KAAKqB,EAAexE,EAAQL,EAAWe,EAAMb,EAAK0C,c,CAI9D,IAAIkC,EAAU,OAAOJ,EAAQhE,KAAK,QAC9B8D,IAAUM,GAAW,MAAMrC,EAAOzC,SACtC8E,GAAWR,EAAM,IAAM,MAAM7B,EAAOzC,QAEpC,MAAMc,EAAS,IAAIiE,OAAOD,EAASL,GACnC,MAAO,CAAE3D,SAAQC,OACnB,CAKA,SAAS4D,EAAaK,EAAsBC,GAC1C,GAAIhB,MAAMC,QAAQc,GAChB,IAAK,MAAME,KAAKF,EAAOL,EAAaO,EAAGD,QAEvCA,EAAKzB,KAAKwB,GAEZ,OAAOC,CACT,CAUA,SAAUL,EACRvE,EACA+C,EACA6B,GAEA,GAAI7B,IAAU/C,EAAOG,OACnB,aAAayE,EAGf,MAAMrB,EAAQvD,EAAO+C,GAErB,GAAmB,UAAfQ,EAAMvC,KACR,IAAK,MAAM8D,KAAOP,EAAQhB,EAAMvD,OAAQ,EAAG4E,EAAKG,eACvCR,EAAQvE,EAAQ+C,EAAQ,EAAG+B,QAGpCF,EAAKzB,KAAKI,SAGLgB,EAAQvE,EAAQ+C,EAAQ,EAAG6B,EACpC,CAKA,SAASJ,EACPxE,EACAL,EACAe,EACA6B,GAEA,IAAIuB,EAAS,GACTkB,EAAY,GACZC,GAAqB,EAEzB,IAAK,MAAM1B,KAASvD,EAClB,GAAmB,SAAfuD,EAAMvC,KAOV,GAAmB,UAAfuC,EAAMvC,MAAmC,aAAfuC,EAAMvC,UAApC,CACE,IAAKiE,IAAuBD,EAC1B,MAAM,IAAIvC,EACR,wBAAwBc,EAAM5B,SAAS4B,EAAMvC,OAC7CuB,GAIe,UAAfgB,EAAMvC,KACR8C,GAAU,IAAIoB,EAAOvF,EAAWsF,EAAqB,GAAKD,OAE1DlB,GAAU,cAGZpD,EAAKyC,KAAKI,GACVyB,EAAY,GACZC,GAAqB,C,MAtBrBnB,GAAU1B,EAAOmB,EAAMtC,OACvB+D,GAAazB,EAAMtC,MACnBgE,MAAuB1B,EAAMtC,MAAMkE,SAASxF,IAyBhD,OAAOmE,CACT,CAKA,SAASoB,EAAOvF,EAAmBqF,GACjC,OAAIA,EAAU7E,OAAS,EACjBR,EAAUQ,OAAS,EAAU,KAAKiC,EAAOzC,EAAYqF,MAClD,SAAS5C,EAAOzC,QAAgByC,EAAO4C,OAE5CrF,EAAUQ,OAAS,EACd,SAASiC,EAAO4C,QAAgB5C,EAAOzC,OAEzC,SAASyC,EAAO4C,MAAc5C,EAAOzC,cAC9C,CAKA,SAASkC,EAAgB7B,GACvB,IAAIiB,EAAQ,GACRO,EAAI,EAER,SAASG,EAAKV,GACZ,MAAMmE,EA2CV,SAASC,EAAW1D,GAClB,MAAO2D,KAAUC,GAAQ5D,EACzB,OAAOG,EAASmB,KAAKqC,IAAUC,EAAKC,MAAOC,GAAS1D,EAAYkB,KAAKwC,GACvE,CA9CmBJ,CAAWpE,IAmD9B,SAASyE,EAAenC,GACtB,OAAIA,GAAwB,SAAfA,EAAMvC,OAAyBe,EAAYkB,KAAKM,EAAMtC,MAAM,GAE3E,CAtDwCyE,CAAe1F,EAAOwB,IAC1D,OAAO4D,EAASnE,EAAQ0E,KAAK/D,UAAUX,E,CAGzC,KAAOO,EAAIxB,EAAOG,QAAQ,CACxB,MAAMoD,EAAQvD,EAAOwB,KAErB,GAAmB,SAAf+B,EAAMvC,KAKV,GAAmB,UAAfuC,EAAMvC,KAKV,GAAmB,UAAfuC,EAAMvC,KAAV,CAKA,GAAmB,aAAfuC,EAAMvC,KAKV,MAAM,IAAIZ,UAAU,uBAAwBmD,EAAcvC,QAJxDC,GAAS,IAAIU,EAAK4B,EAAM5B,O,MALxBV,GAAS,IAAIU,EAAK4B,EAAM5B,aALxBV,GAAS,IAAIY,EAAgB0B,EAAMvD,gBALnCiB,GAASgB,EAAWsB,EAAMtC,M,CAsB9B,OAAOA,CACT,C,OA5cA7B,EAAAqD,Y,KC/HA,MAAMmD,EAAc,CAChBvD,UAAWwD,YACXpD,UAAWqD,Y,MACXzG,Q,QACAC,U,MACAgB,Q,UACAsB,Y,aACAjB,gB","ignoreList":[]}
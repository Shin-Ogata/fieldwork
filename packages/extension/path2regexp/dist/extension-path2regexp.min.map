{"version":3,"names":["DEFAULT_DELIMITER","NOOP_VALUE","value","ID_CHAR","SIMPLE_TOKENS","Iter","constructor","tokens","this","index","peek","tryConsume","type","token","consume","undefined","nextType","TypeError","text","result","modifier","TokenData","delimiter","parse","str","options","encodePath","it","lexer","chars","i","length","push","pos","count","pattern","name","test","key","path","String","next","asterisk","escape","separator","open","prefix","suffix","dist","parse_1","compile_1","compile","data","compileTokens","encode","encodeURIComponent","loose","validate","reFlags","flags","stringify","toStringify","keyToRegexp","toKeyRegexp","encoders","map","fn","tokenToFunction","encodeValue","repeated","optional","Array","isArray","join","validRe","RegExp","JSON","encoder","match_1","match","decode","decodeURIComponent","keys","re","tokensToRegexp","decoders","split","pathname","m","exec","params","Object","create","decoder","replace","looseReplacer","sensitive","trailing","start","end","segmentPattern","mod","pathToRegexp_1","pathToRegexp","regexp","assign","path2regexp"],"sources":["cdp:///@cdp/extension-path2regexp/path-to-regexp/src/index.ts","cdp:///@cdp/extension-path2regexp/index.ts"],"sourcesContent":["const DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = (value: string) => value;\nconst ID_CHAR = /^\\p{XID_Continue}$/u;\n\n/**\n * Encode a string into another string.\n */\nexport type Encode = (value: string) => string;\n\n/**\n * Decode a string into another string.\n */\nexport type Decode = (value: string) => string;\n\nexport interface ParseOptions {\n  /**\n   * Set the default delimiter for repeat parameters. (default: `'/'`)\n   */\n  delimiter?: string;\n  /**\n   * Function for encoding input strings for output into path.\n   */\n  encodePath?: Encode;\n}\n\nexport interface PathToRegexpOptions extends ParseOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Allow delimiter to be arbitrarily repeated. (default: `true`)\n   */\n  loose?: boolean;\n  /**\n   * When `true` the regexp will match to the end of the string. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * When `true` the regexp will match from the beginning of the string. (default: `true`)\n   */\n  start?: boolean;\n  /**\n   * When `true` the regexp allows an optional trailing delimiter to match. (default: `true`)\n   */\n  trailing?: boolean;\n}\n\nexport interface MatchOptions extends PathToRegexpOptions {\n  /**\n   * Function for decoding strings for params, or `false` to disable entirely. (default: `decodeURIComponent`)\n   */\n  decode?: Decode | false;\n}\n\nexport interface CompileOptions extends ParseOptions {\n  /**\n   * When `true` the validation will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Allow delimiter to be arbitrarily repeated. (default: `true`)\n   */\n  loose?: boolean;\n  /**\n   * When `false` the function can produce an invalid (unmatched) path. (default: `true`)\n   */\n  validate?: boolean;\n  /**\n   * Function for encoding input strings for output into the path, or `false` to disable entirely. (default: `encodeURIComponent`)\n   */\n  encode?: Encode | false;\n}\n\ntype TokenType =\n  | \"{\"\n  | \"}\"\n  | \"*\"\n  | \"+\"\n  | \"?\"\n  | \"NAME\"\n  | \"PATTERN\"\n  | \"CHAR\"\n  | \"ESCAPED\"\n  | \"END\"\n  // Reserved for use.\n  | \"!\"\n  | \"@\"\n  | \",\"\n  | \";\";\n\n/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type: TokenType;\n  index: number;\n  value: string;\n}\n\nconst SIMPLE_TOKENS: Record<string, TokenType> = {\n  \"!\": \"!\",\n  \"@\": \"@\",\n  \";\": \";\",\n  \",\": \",\",\n  \"*\": \"*\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"{\": \"{\",\n  \"}\": \"}\",\n};\n\n/**\n * Tokenize input string.\n */\nfunction lexer(str: string) {\n  const chars = [...str];\n  const tokens: LexToken[] = [];\n  let i = 0;\n\n  while (i < chars.length) {\n    const value = chars[i];\n    const type = SIMPLE_TOKENS[value];\n\n    if (type) {\n      tokens.push({ type, index: i++, value });\n      continue;\n    }\n\n    if (value === \"\\\\\") {\n      tokens.push({ type: \"ESCAPED\", index: i++, value: chars[i++] });\n      continue;\n    }\n\n    if (value === \":\") {\n      let name = \"\";\n\n      while (ID_CHAR.test(chars[++i])) {\n        name += chars[i];\n      }\n\n      if (!name) {\n        throw new TypeError(`Missing parameter name at ${i}`);\n      }\n\n      tokens.push({ type: \"NAME\", index: i, value: name });\n      continue;\n    }\n\n    if (value === \"(\") {\n      const pos = i++;\n      let count = 1;\n      let pattern = \"\";\n\n      if (chars[i] === \"?\") {\n        throw new TypeError(`Pattern cannot start with \"?\" at ${i}`);\n      }\n\n      while (i < chars.length) {\n        if (chars[i] === \"\\\\\") {\n          pattern += chars[i++] + chars[i++];\n          continue;\n        }\n\n        if (chars[i] === \")\") {\n          count--;\n          if (count === 0) {\n            i++;\n            break;\n          }\n        } else if (chars[i] === \"(\") {\n          count++;\n          if (chars[i + 1] !== \"?\") {\n            throw new TypeError(`Capturing groups are not allowed at ${i}`);\n          }\n        }\n\n        pattern += chars[i++];\n      }\n\n      if (count) throw new TypeError(`Unbalanced pattern at ${pos}`);\n      if (!pattern) throw new TypeError(`Missing pattern at ${pos}`);\n\n      tokens.push({ type: \"PATTERN\", index: i, value: pattern });\n      continue;\n    }\n\n    tokens.push({ type: \"CHAR\", index: i, value: chars[i++] });\n  }\n\n  tokens.push({ type: \"END\", index: i, value: \"\" });\n\n  return new Iter(tokens);\n}\n\nclass Iter {\n  index = 0;\n\n  constructor(private tokens: LexToken[]) {}\n\n  peek(): LexToken {\n    return this.tokens[this.index];\n  }\n\n  tryConsume(type: LexToken[\"type\"]): string | undefined {\n    const token = this.peek();\n    if (token.type !== type) return;\n    this.index++;\n    return token.value;\n  }\n\n  consume(type: LexToken[\"type\"]): string {\n    const value = this.tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = this.peek();\n    throw new TypeError(\n      `Unexpected ${nextType} at ${index}, expected ${type}: https://git.new/pathToRegexpError`,\n    );\n  }\n\n  text(): string {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = this.tryConsume(\"CHAR\") || this.tryConsume(\"ESCAPED\"))) {\n      result += value;\n    }\n    return result;\n  }\n\n  modifier(): string {\n    return (\n      this.tryConsume(\"?\") || this.tryConsume(\"*\") || this.tryConsume(\"+\") || \"\"\n    );\n  }\n}\n\n/**\n * Tokenized path instance. Can we passed around instead of string.\n */\nexport class TokenData {\n  constructor(\n    public readonly tokens: Token[],\n    public readonly delimiter: string,\n  ) {}\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): TokenData {\n  const { delimiter = DEFAULT_DELIMITER, encodePath = NOOP_VALUE } = options;\n  const tokens: Token[] = [];\n  const it = lexer(str);\n  let key = 0;\n\n  do {\n    const path = it.text();\n    if (path) tokens.push(encodePath(path));\n\n    const name = it.tryConsume(\"NAME\");\n    const pattern = it.tryConsume(\"PATTERN\");\n\n    if (name || pattern) {\n      tokens.push({\n        name: name || String(key++),\n        pattern,\n      });\n\n      const next = it.peek();\n      if (next.type === \"*\") {\n        throw new TypeError(\n          `Unexpected * at ${next.index}, you probably want \\`/*\\` or \\`{/:foo}*\\`: https://git.new/pathToRegexpError`,\n        );\n      }\n\n      continue;\n    }\n\n    const asterisk = it.tryConsume(\"*\");\n    if (asterisk) {\n      tokens.push({\n        name: String(key++),\n        pattern: `[^${escape(delimiter)}]*`,\n        modifier: \"*\",\n        separator: delimiter,\n      });\n      continue;\n    }\n\n    const open = it.tryConsume(\"{\");\n    if (open) {\n      const prefix = it.text();\n      const name = it.tryConsume(\"NAME\");\n      const pattern = it.tryConsume(\"PATTERN\");\n      const suffix = it.text();\n      const separator = it.tryConsume(\";\") ? it.text() : prefix + suffix;\n\n      it.consume(\"}\");\n\n      const modifier = it.modifier();\n\n      tokens.push({\n        name: name || (pattern ? String(key++) : \"\"),\n        prefix: encodePath(prefix),\n        suffix: encodePath(suffix),\n        pattern,\n        modifier,\n        separator,\n      });\n      continue;\n    }\n\n    it.consume(\"END\");\n    break;\n  } while (true);\n\n  return new TokenData(tokens, delimiter);\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends object = object>(\n  path: Path,\n  options: CompileOptions = {},\n) {\n  const data = path instanceof TokenData ? path : parse(path, options);\n  return compileTokens<P>(data, options);\n}\n\nexport type ParamData = Partial<Record<string, string | string[]>>;\nexport type PathFunction<P extends ParamData> = (data?: P) => string;\n\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(\n  token: Token,\n  encode: Encode | false,\n): (data: ParamData) => string {\n  if (typeof token === \"string\") {\n    return () => token;\n  }\n\n  const encodeValue = encode || NOOP_VALUE;\n  const repeated = token.modifier === \"+\" || token.modifier === \"*\";\n  const optional = token.modifier === \"?\" || token.modifier === \"*\";\n  const { prefix = \"\", suffix = \"\", separator = \"\" } = token;\n\n  if (encode && repeated) {\n    const stringify = (value: string, index: number) => {\n      if (typeof value !== \"string\") {\n        throw new TypeError(`Expected \"${token.name}/${index}\" to be a string`);\n      }\n      return encodeValue(value);\n    };\n\n    const compile = (value: unknown) => {\n      if (!Array.isArray(value)) {\n        throw new TypeError(`Expected \"${token.name}\" to be an array`);\n      }\n\n      if (value.length === 0) return \"\";\n\n      return prefix + value.map(stringify).join(separator) + suffix;\n    };\n\n    if (optional) {\n      return (data): string => {\n        const value = data[token.name];\n        if (value == null) return \"\";\n        return value.length ? compile(value) : \"\";\n      };\n    }\n\n    return (data): string => {\n      const value = data[token.name];\n      return compile(value);\n    };\n  }\n\n  const stringify = (value: unknown) => {\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n    return prefix + encodeValue(value) + suffix;\n  };\n\n  if (optional) {\n    return (data): string => {\n      const value = data[token.name];\n      if (value == null) return \"\";\n      return stringify(value);\n    };\n  }\n\n  return (data): string => {\n    const value = data[token.name];\n    return stringify(value);\n  };\n}\n\n/**\n * Transform tokens into a path building function.\n */\nfunction compileTokens<P extends ParamData>(\n  data: TokenData,\n  options: CompileOptions,\n): PathFunction<P> {\n  const {\n    encode = encodeURIComponent,\n    loose = true,\n    validate = true,\n  } = options;\n  const reFlags = flags(options);\n  const stringify = toStringify(loose, data.delimiter);\n  const keyToRegexp = toKeyRegexp(stringify, data.delimiter);\n\n  // Compile all the tokens into regexps.\n  const encoders: Array<(data: ParamData) => string> = data.tokens.map(\n    (token) => {\n      const fn = tokenToFunction(token, encode);\n      if (!validate || typeof token === \"string\") return fn;\n\n      const pattern = keyToRegexp(token);\n      const validRe = new RegExp(`^${pattern}$`, reFlags);\n\n      return (data) => {\n        const value = fn(data);\n        if (!validRe.test(value)) {\n          throw new TypeError(\n            `Invalid value for \"${token.name}\": ${JSON.stringify(value)}`,\n          );\n        }\n        return value;\n      };\n    },\n  );\n\n  return function path(data: Record<string, any> = {}) {\n    let path = \"\";\n    for (const encoder of encoders) path += encoder(data);\n    return path;\n  };\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends ParamData> {\n  path: string;\n  index: number;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends ParamData> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends ParamData> = (path: string) => Match<P>;\n\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nexport function match<P extends ParamData>(\n  path: Path,\n  options: MatchOptions = {},\n): MatchFunction<P> {\n  const { decode = decodeURIComponent, loose = true } = options;\n  const data = path instanceof TokenData ? path : parse(path, options);\n  const stringify = toStringify(loose, data.delimiter);\n  const keys: Key[] = [];\n  const re = tokensToRegexp(data, keys, options);\n\n  const decoders = keys.map((key) => {\n    if (decode && (key.modifier === \"+\" || key.modifier === \"*\")) {\n      const re = new RegExp(stringify(key.separator || \"\"), \"g\");\n      return (value: string) => value.split(re).map(decode);\n    }\n\n    return decode || NOOP_VALUE;\n  });\n\n  return function match(pathname: string) {\n    const m = re.exec(pathname);\n    if (!m) return false;\n\n    const { 0: path, index } = m;\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n\n    return { path, index, params };\n  };\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escape(str: string) {\n  return str.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g, \"\\\\$1\");\n}\n\n/**\n * Escape and repeat loose characters for regular expressions.\n */\nfunction looseReplacer(value: string, loose: string) {\n  return loose ? `${escape(value)}+` : escape(value);\n}\n\n/**\n * Encode all non-delimiter characters using the encode function.\n */\nfunction toStringify(loose: boolean, delimiter: string) {\n  if (!loose) return escape;\n\n  const re = new RegExp(`[^${escape(delimiter)}]+|(.)`, \"g\");\n  return (value: string) => value.replace(re, looseReplacer);\n}\n\n/**\n * Get the flags for a regexp from the options.\n */\nfunction flags(options: { sensitive?: boolean }) {\n  return options.sensitive ? \"\" : \"i\";\n}\n\n/**\n * A key is a capture group in the regex.\n */\nexport interface Key {\n  name: string;\n  prefix?: string;\n  suffix?: string;\n  pattern?: string;\n  modifier?: string;\n  separator?: string;\n}\n\n/**\n * A token is a string (nothing special) or key metadata (capture group).\n */\nexport type Token = string | Key;\n\n/**\n * Expose a function for taking tokens and returning a RegExp.\n */\nfunction tokensToRegexp(\n  data: TokenData,\n  keys: Key[],\n  options: PathToRegexpOptions,\n): RegExp {\n  const { trailing = true, start = true, end = true, loose = true } = options;\n  const stringify = toStringify(loose, data.delimiter);\n  const keyToRegexp = toKeyRegexp(stringify, data.delimiter);\n  let pattern = start ? \"^\" : \"\";\n\n  for (const token of data.tokens) {\n    if (typeof token === \"string\") {\n      pattern += stringify(token);\n    } else {\n      if (token.name) keys.push(token);\n      pattern += keyToRegexp(token);\n    }\n  }\n\n  if (trailing) pattern += `(?:${stringify(data.delimiter)})?`;\n  pattern += end ? \"$\" : `(?=${escape(data.delimiter)}|$)`;\n\n  return new RegExp(pattern, flags(options));\n}\n\n/**\n * Convert a token into a regexp string (re-used for path validation).\n */\nfunction toKeyRegexp(stringify: Encode, delimiter: string) {\n  const segmentPattern = `[^${escape(delimiter)}]+?`;\n\n  return (key: Key) => {\n    const prefix = key.prefix ? stringify(key.prefix) : \"\";\n    const suffix = key.suffix ? stringify(key.suffix) : \"\";\n    const modifier = key.modifier || \"\";\n\n    if (key.name) {\n      const pattern = key.pattern || segmentPattern;\n      if (key.modifier === \"+\" || key.modifier === \"*\") {\n        const mod = key.modifier === \"*\" ? \"?\" : \"\";\n        const split = key.separator ? stringify(key.separator) : \"\";\n        return `(?:${prefix}((?:${pattern})(?:${split}(?:${pattern}))*)${suffix})${mod}`;\n      }\n      return `(?:${prefix}(${pattern})${suffix})${modifier}`;\n    }\n\n    return `(?:${prefix}${suffix})${modifier}`;\n  };\n}\n\n/**\n * Repeated and simple input types.\n */\nexport type Path = string | TokenData;\n\nexport type PathRegExp = RegExp & { keys: Key[] };\n\n/**\n * Normalize the given path string, returning a regular expression.\n *\n * An empty array can be passed in for the keys, which will hold the\n * placeholder key descriptions. For example, using `/user/:id`, `keys` will\n * contain `[{ name: 'id', delimiter: '/', optional: false, repeat: false }]`.\n */\nexport function pathToRegexp(path: Path, options: PathToRegexpOptions = {}) {\n  const data = path instanceof TokenData ? path : parse(path, options);\n  const keys: Key[] = [];\n  const regexp = tokensToRegexp(data, keys, options);\n  return Object.assign(regexp, { keys });\n}\n","/* eslint-disable\n    @typescript-eslint/no-namespace,\n */\n\nimport {\n    Encode as p2rEncode,\n    Decode as p2rDecode,\n    ParseOptions as p2rParseOptions,\n    PathToRegexpOptions as p2rPathToRegexpOptions,\n    MatchOptions as p2rMatchOptions,\n    CompileOptions as p2rCompileOptions,\n    TokenData as p2rTokenData,\n    ParamData as p2rParamData,\n    PathFunction as p2rPathFunction,\n    MatchResult as p2rMatchResult,\n    Match as p2rMatch,\n    MatchFunction as p2rMatchFunction,\n    Key as p2rKey,\n    Token as p2rToken,\n    Path as p2rPath,\n    PathRegExp as p2rPathRegExp,\n    parse,\n    compile,\n    match,\n    pathToRegexp,\n} from 'path-to-regexp';\n\ndeclare namespace path2regexp {\n    export type Encode = p2rEncode;\n    export type Decode = p2rDecode;\n    export type ParseOptions = p2rParseOptions;\n    export type PathToRegexpOptions = p2rPathToRegexpOptions;\n    export type MatchOptions = p2rMatchOptions;\n    export type CompileOptions = p2rCompileOptions;\n    export type TokenData = p2rTokenData;\n    export type ParamData = p2rParamData;\n    export type PathFunction<P extends ParamData> = p2rPathFunction<P>;\n    export type MatchResult<P extends ParamData> = p2rMatchResult<P>;\n    export type Match<P extends ParamData> = p2rMatch<P>;\n    export type MatchFunction<P extends ParamData> = p2rMatchFunction<P>;\n    export type Key = p2rKey;\n    export type Token = p2rToken;\n    export type Path = p2rPath;\n    export type PathRegExp = p2rPathRegExp;\n}\n\nconst path2regexp = {\n    parse,\n    compile,\n    match,\n    pathToRegexp,\n};\n\nexport { path2regexp };\n"],"mappings":";;;;oZAAA,MAAMA,EAAoB,IACpBC,EAAcC,GAAkBA,EAChCC,EAAU,sBAkGVC,EAA2C,CAC/C,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,KAsFP,MAAMC,EAGJ,WAAAC,CAAoBC,GAAAC,KAAMD,OAANA,EAFpBC,KAAKC,MAAG,C,CAIR,IAAAC,GACE,OAAOF,KAAKD,OAAOC,KAAKC,M,CAG1B,UAAAE,CAAWC,GACT,MAAMC,EAAQL,KAAKE,OACnB,GAAIG,EAAMD,OAASA,EAEnB,OADAJ,KAAKC,QACEI,EAAMX,K,CAGf,OAAAY,CAAQF,GACN,MAAMV,EAAQM,KAAKG,WAAWC,GAC9B,QAAcG,IAAVb,EAAqB,OAAOA,EAChC,MAAQU,KAAMI,EAAQP,MAAEA,GAAUD,KAAKE,OACvC,MAAM,IAAIO,UACR,cAAcD,QAAeP,eAAmBG,uC,CAIpD,IAAAM,GACE,IACIhB,EADAiB,EAAS,GAEb,KAAQjB,EAAQM,KAAKG,WAAW,SAAWH,KAAKG,WAAW,YACzDQ,GAAUjB,EAEZ,OAAOiB,C,CAGT,QAAAC,GACE,OACEZ,KAAKG,WAAW,MAAQH,KAAKG,WAAW,MAAQH,KAAKG,WAAW,MAAQ,E,EAQ9E,MAAaU,EACX,WAAAf,CACkBC,EACAe,GADAd,KAAMD,OAANA,EACAC,KAASc,UAATA,C,EAOpB,SAAgBC,EAAMC,EAAaC,EAAwB,IACzD,MAAMH,UAAEA,EAAYtB,EAAiB0B,WAAEA,EAAazB,GAAewB,EAC7DlB,EAAkB,GAClBoB,EAzIR,SAASC,EAAMJ,GACb,MAAMK,EAAQ,IAAIL,GACZjB,EAAqB,GAC3B,IAAIuB,EAAI,EAER,KAAOA,EAAID,EAAME,QAAQ,CACvB,MAAM7B,EAAQ2B,EAAMC,GACdlB,EAAOR,EAAcF,GAE3B,GAAIU,EACFL,EAAOyB,KAAK,CAAEpB,OAAMH,MAAOqB,IAAK5B,eAIlC,GAAc,OAAVA,EAKJ,GAAc,MAAVA,EAeJ,GAAc,MAAVA,EAsCJK,EAAOyB,KAAK,CAAEpB,KAAM,OAAQH,MAAOqB,EAAG5B,MAAO2B,EAAMC,WAtCnD,CACE,MAAMG,EAAMH,IACZ,IAAII,EAAQ,EACRC,EAAU,GAEd,GAAiB,MAAbN,EAAMC,GACR,MAAM,IAAIb,UAAU,oCAAoCa,KAG1D,KAAOA,EAAID,EAAME,QACf,GAAiB,OAAbF,EAAMC,GAAV,CAKA,GAAiB,MAAbD,EAAMC,IAER,GADAI,IACc,IAAVA,EAAa,CACfJ,IACA,KACD,OACI,GAAiB,MAAbD,EAAMC,KACfI,IACqB,MAAjBL,EAAMC,EAAI,IACZ,MAAM,IAAIb,UAAU,uCAAuCa,KAI/DK,GAAWN,EAAMC,IAfhB,MAFCK,GAAWN,EAAMC,KAAOD,EAAMC,KAoBlC,GAAII,EAAO,MAAM,IAAIjB,UAAU,yBAAyBgB,KACxD,IAAKE,EAAS,MAAM,IAAIlB,UAAU,sBAAsBgB,KAExD1B,EAAOyB,KAAK,CAAEpB,KAAM,UAAWH,MAAOqB,EAAG5B,MAAOiC,GAEjD,KAnDD,CACE,IAAIC,EAAO,GAEX,KAAOjC,EAAQkC,KAAKR,IAAQC,KAC1BM,GAAQP,EAAMC,GAGhB,IAAKM,EACH,MAAM,IAAInB,UAAU,6BAA6Ba,KAGnDvB,EAAOyB,KAAK,CAAEpB,KAAM,OAAQH,MAAOqB,EAAG5B,MAAOkC,GAE9C,MAjBC7B,EAAOyB,KAAK,CAAEpB,KAAM,UAAWH,MAAOqB,IAAK5B,MAAO2B,EAAMC,MA0D3D,CAID,OAFAvB,EAAOyB,KAAK,CAAEpB,KAAM,MAAOH,MAAOqB,EAAG5B,MAAO,KAErC,IAAIG,EAAKE,EAClB,CA2DaqB,CAAMJ,GACjB,IAAIc,EAAM,EAEV,OAAG,EACD,MAAMC,EAAOZ,EAAGT,OACZqB,GAAMhC,EAAOyB,KAAKN,EAAWa,IAEjC,MAAMH,EAAOT,EAAGhB,WAAW,QACrBwB,EAAUR,EAAGhB,WAAW,WAE9B,GAAIyB,GAAQD,EAAS,CACnB5B,EAAOyB,KAAK,CACVI,KAAMA,GAAQI,OAAOF,KACrBH,YAGF,MAAMM,EAAOd,EAAGjB,OAChB,GAAkB,MAAd+B,EAAK7B,KACP,MAAM,IAAIK,UACR,mBAAmBwB,EAAKhC,sFAI5B,QACD,CAED,MAAMiC,EAAWf,EAAGhB,WAAW,KAC/B,GAAI+B,EAAU,CACZnC,EAAOyB,KAAK,CACVI,KAAMI,OAAOF,KACbH,QAAS,KAAKQ,EAAOrB,OACrBF,SAAU,IACVwB,UAAWtB,IAEb,QACD,CAED,MAAMuB,EAAOlB,EAAGhB,WAAW,KAC3B,IAAIkC,EAAJ,CAsBAlB,EAAGb,QAAQ,OACX,KAHC,CApBD,CACE,MAAMgC,EAASnB,EAAGT,OACZkB,EAAOT,EAAGhB,WAAW,QACrBwB,EAAUR,EAAGhB,WAAW,WACxBoC,EAASpB,EAAGT,OACZ0B,EAAYjB,EAAGhB,WAAW,KAAOgB,EAAGT,OAAS4B,EAASC,EAE5DpB,EAAGb,QAAQ,KAEX,MAAMM,EAAWO,EAAGP,WAEpBb,EAAOyB,KAAK,CACVI,KAAMA,IAASD,EAAUK,OAAOF,KAAS,IACzCQ,OAAQpB,EAAWoB,GACnBC,OAAQrB,EAAWqB,GACnBZ,UACAf,WACAwB,aAGH,CAIF,CAAQ,CAAR,CAED,OAAO,IAAIvB,EAAUd,EAAQe,EAC/B,CAzEC0B,EAAA3B,YAKD,IAoEC4B,EAAAD,EAAAzB,QAKD,IAMC2B,EAAAF,EAAAG,QAND,SAAgBA,EACdZ,EACAd,EAA0B,IAE1B,MAAM2B,EAAOb,aAAgBlB,EAAYkB,EAAOhB,EAAMgB,EAAMd,GAC5D,OA8EF,SAAS4B,EACPD,EACA3B,GAEA,MAAM6B,OACJA,EAASC,mBAAkBC,MAC3BA,GAAQ,EAAIC,SACZA,GAAW,GACThC,EACEiC,EAAUC,EAAMlC,GAChBmC,EAAYC,EAAYL,EAAOJ,EAAK9B,WACpCwC,EAAcC,EAAYH,EAAWR,EAAK9B,WAG1C0C,EAA+CZ,EAAK7C,OAAO0D,KAC9DpD,IACC,MAAMqD,EArFZ,SAASC,EACPtD,EACAyC,GAEA,GAAqB,iBAAVzC,EACT,MAAO,IAAMA,EAGf,MAAMuD,EAAcd,GAAUrD,EACxBoE,EAA8B,MAAnBxD,EAAMO,UAAuC,MAAnBP,EAAMO,SAC3CkD,EAA8B,MAAnBzD,EAAMO,UAAuC,MAAnBP,EAAMO,UAC3C0B,OAAEA,EAAS,GAAEC,OAAEA,EAAS,GAAEH,UAAEA,EAAY,IAAO/B,EAErD,GAAIyC,GAAUe,EAAU,CACtB,MAAMT,EAAY,CAAC1D,EAAeO,KAChC,GAAqB,iBAAVP,EACT,MAAM,IAAIe,UAAU,aAAaJ,EAAMuB,QAAQ3B,qBAEjD,OAAO2D,EAAYlE,EAAM,EAGrBiD,EAAWjD,IACf,IAAKqE,MAAMC,QAAQtE,GACjB,MAAM,IAAIe,UAAU,aAAaJ,EAAMuB,wBAGzC,OAAqB,IAAjBlC,EAAM6B,OAAqB,GAExBe,EAAS5C,EAAM+D,IAAIL,GAAWa,KAAK7B,GAAaG,CAAM,EAG/D,OAAIuB,EACMlB,IACN,MAAMlD,EAAQkD,EAAKvC,EAAMuB,MACzB,OAAa,MAATlC,EAAsB,GACnBA,EAAM6B,OAASoB,EAAQjD,GAAS,EAAE,EAIrCkD,IACN,MAAMlD,EAAQkD,EAAKvC,EAAMuB,MACzB,OAAOe,EAAQjD,EAAM,CAExB,CAED,MAAM0D,EAAa1D,IACjB,GAAqB,iBAAVA,EACT,MAAM,IAAIe,UAAU,aAAaJ,EAAMuB,wBAEzC,OAAOU,EAASsB,EAAYlE,GAAS6C,CAAM,EAG7C,GAAIuB,EACF,OAAQlB,IACN,MAAMlD,EAAQkD,EAAKvC,EAAMuB,MACzB,OAAa,MAATlC,EAAsB,GACnB0D,EAAU1D,EAAM,EAI3B,OAAQkD,IACN,MAAMlD,EAAQkD,EAAKvC,EAAMuB,MACzB,OAAOwB,EAAU1D,EAAM,CAE3B,CAqBiBiE,CAAgBtD,EAAOyC,GAClC,IAAKG,GAA6B,iBAAV5C,EAAoB,OAAOqD,EAEnD,MAAM/B,EAAU2B,EAAYjD,GACtB6D,EAAU,IAAIC,OAAO,IAAIxC,KAAYuB,GAE3C,OAAQN,IACN,MAAMlD,EAAQgE,EAAGd,GACjB,IAAKsB,EAAQrC,KAAKnC,GAChB,MAAM,IAAIe,UACR,sBAAsBJ,EAAMuB,UAAUwC,KAAKhB,UAAU1D,MAGzD,OAAOA,CAAK,CACb,IAIL,OAAO,SAASqC,EAAKa,EAA4B,IAC/C,IAAIb,EAAO,GACX,IAAK,MAAMsC,KAAWb,EAAUzB,GAAQsC,EAAQzB,GAChD,OAAOb,CACT,CACF,CArHSc,CAAiBD,EAAM3B,EAChC,EA4IA,IAoCCqD,EAAA9B,EAAA+B,MApCD,SAAgBA,EACdxC,EACAd,EAAwB,IAExB,MAAMuD,OAAEA,EAASC,mBAAkBzB,MAAEA,GAAQ,GAAS/B,EAChD2B,EAAOb,aAAgBlB,EAAYkB,EAAOhB,EAAMgB,EAAMd,GACtDmC,EAAYC,EAAYL,EAAOJ,EAAK9B,WACpC4D,EAAc,GACdC,EAAKC,EAAehC,EAAM8B,EAAMzD,GAEhC4D,EAAWH,EAAKjB,KAAK3B,IACzB,GAAI0C,IAA4B,MAAjB1C,EAAIlB,UAAqC,MAAjBkB,EAAIlB,UAAmB,CAC5D,MAAM+D,EAAK,IAAIR,OAAOf,EAAUtB,EAAIM,WAAa,IAAK,KACtD,OAAQ1C,GAAkBA,EAAMoF,MAAMH,GAAIlB,IAAIe,EAC/C,CAED,OAAOA,GAAU/E,CAAU,IAG7B,OAAO,SAAS8E,EAAMQ,GACpB,MAAMC,EAAIL,EAAGM,KAAKF,GAClB,IAAKC,EAAG,OAAO,EAEf,MAAQ,EAAGjD,EAAI9B,MAAEA,GAAU+E,EACrBE,EAASC,OAAOC,OAAO,MAE7B,IAAK,IAAI9D,EAAI,EAAGA,EAAI0D,EAAEzD,OAAQD,IAAK,CACjC,QAAaf,IAATyE,EAAE1D,GAAkB,SAExB,MAAMQ,EAAM4C,EAAKpD,EAAI,GACf+D,EAAUR,EAASvD,EAAI,GAC7B4D,EAAOpD,EAAIF,MAAQyD,EAAQL,EAAE1D,GAC9B,CAED,MAAO,CAAES,OAAM9B,QAAOiF,SACxB,CACF,EAKA,SAAS/C,EAAOnB,GACd,OAAOA,EAAIsE,QAAQ,4BAA6B,OAClD,CAKA,SAASC,EAAc7F,EAAesD,GACpC,OAAOA,EAAQ,GAAGb,EAAOzC,MAAYyC,EAAOzC,EAC9C,CAKA,SAAS2D,EAAYL,EAAgBlC,GACnC,IAAKkC,EAAO,OAAOb,EAEnB,MAAMwC,EAAK,IAAIR,OAAO,KAAKhC,EAAOrB,WAAoB,KACtD,OAAQpB,GAAkBA,EAAM4F,QAAQX,EAAIY,EAC9C,CAKA,SAASpC,EAAMlC,GACb,OAAOA,EAAQuE,UAAY,GAAK,GAClC,CAsBA,SAASZ,EACPhC,EACA8B,EACAzD,GAEA,MAAMwE,SAAEA,GAAW,EAAIC,MAAEA,GAAQ,EAAIC,IAAEA,GAAM,EAAI3C,MAAEA,GAAQ,GAAS/B,EAC9DmC,EAAYC,EAAYL,EAAOJ,EAAK9B,WACpCwC,EAAcC,EAAYH,EAAWR,EAAK9B,WAChD,IAAIa,EAAU+D,EAAQ,IAAM,GAE5B,IAAK,MAAMrF,KAASuC,EAAK7C,OACF,iBAAVM,EACTsB,GAAWyB,EAAU/C,IAEjBA,EAAMuB,MAAM8C,EAAKlD,KAAKnB,GAC1BsB,GAAW2B,EAAYjD,IAO3B,OAHIoF,IAAU9D,GAAW,MAAMyB,EAAUR,EAAK9B,gBAC9Ca,GAAWgE,EAAM,IAAM,MAAMxD,EAAOS,EAAK9B,gBAElC,IAAIqD,OAAOxC,EAASwB,EAAMlC,GACnC,CAKA,SAASsC,EAAYH,EAAmBtC,GACtC,MAAM8E,EAAiB,KAAKzD,EAAOrB,QAEnC,OAAQgB,IACN,MAAMQ,EAASR,EAAIQ,OAASc,EAAUtB,EAAIQ,QAAU,GAC9CC,EAAST,EAAIS,OAASa,EAAUtB,EAAIS,QAAU,GAC9C3B,EAAWkB,EAAIlB,UAAY,GAEjC,GAAIkB,EAAIF,KAAM,CACZ,MAAMD,EAAUG,EAAIH,SAAWiE,EAC/B,GAAqB,MAAjB9D,EAAIlB,UAAqC,MAAjBkB,EAAIlB,SAAkB,CAChD,MAAMiF,EAAuB,MAAjB/D,EAAIlB,SAAmB,IAAM,GACnCkE,EAAQhD,EAAIM,UAAYgB,EAAUtB,EAAIM,WAAa,GACzD,MAAO,MAAME,QAAaX,QAAcmD,OAAWnD,QAAcY,KAAUsD,GAC5E,CACD,MAAO,MAAMvD,KAAUX,KAAWY,KAAU3B,GAC7C,CAED,MAAO,MAAM0B,IAASC,KAAU3B,GAAU,CAE9C,CAgBAkF,EAKCtD,EAAAuD,aALD,SAAgBA,EAAahE,EAAYd,EAA+B,IACtE,MAAM2B,EAAOb,aAAgBlB,EAAYkB,EAAOhB,EAAMgB,EAAMd,GACtDyD,EAAc,GACdsB,EAASpB,EAAehC,EAAM8B,EAAMzD,GAC1C,OAAOkE,OAAOc,OAAOD,EAAQ,CAAEtB,QACjC,ECpkBA,MAAMwB,EAAc,C,MAChBnF,E,QACA4B,E,MACA4B,E,aACAwB,G","ignoreList":[]}